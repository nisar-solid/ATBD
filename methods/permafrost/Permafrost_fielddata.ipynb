{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b24af1-1da8-4c30-975c-c78c8ae55e6b",
   "metadata": {},
   "source": [
    "## Process Fielddata\n",
    "\n",
    "**Code authored by:** Andrew Johnson, Simon Zwieback, Franz Meyer, Jie Chen</br>\n",
    "2024\n",
    "\n",
    "This notebook takes the field observations and combines them into a single surface displacement for each field site, so that they can be properly compared to InSAR products.\n",
    "\n",
    "NOTE: The field data will be added to the Cal/Val database. Before then, the 2023 data is provided by a set of small .csv files included here. \n",
    "\n",
    "### Prepare notebook environment\n",
    "\n",
    "First we import functions, set directories, and the site metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d15576-f694-44e1-9f30-9fc2217afa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from solid_utils import permafrost_utils as pu\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6eb75-5e00-4066-8c5c-57e02255bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "site='NorthSlopeEastD102'\n",
    "year=2025\n",
    "\n",
    "base_dir = Path.cwd()\n",
    "work_dir = base_dir/'work'/'permafrost_ouputs'/site/str(year)\n",
    "field_dir = base_dir/'fielddata'\n",
    "\n",
    "print(\"Field directory:\", field_dir)\n",
    "work_dir.mkdir(parents=True, exist_ok=True)\n",
    "field_dir.mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b56408-d2b7-4b0d-a179-357f94a14dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldsites = ['HV','HVE','IC','SM']\n",
    "fieldsitenames = ['Happy Valley','Happy Valley East','Ice Cut','Slope Mountain']\n",
    "fieldsitelocs = [[69.15478,-148.84382],\n",
    "                 [69.15531,-148.83792],\n",
    "                 [69.04113,-148.83162],\n",
    "                 [68.43289,-148.94216]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff21110-a376-413a-a651-364b968796ce",
   "metadata": {},
   "source": [
    "### Open Field Data\n",
    "\n",
    "Each field site covers a 100 by 100 m square of the tundra. We use a fixed benchmark, usually a PVC pipe frozen into a several-meter deep borehole as a non-deforming point on the terrain. There are 3 transects, each of 100 m in length and spaced 50 m apart in order to cover the entire site. Ever 2 meters along the transect we marked a point by a nail in the ground. In the field we use GNSS and leveling (surveying) to measure the elevation of each of these points along the transects relative to the fixed benchmark. These measurements are made at the beginning and end of the summer when the surface is snow-free.\n",
    "\n",
    "The first step is to open the field data from the .csv files.\n",
    "\n",
    "In these files, the 'pointname' column has the format Txxyy: xx is the transact number, yy is the point number in each transact. yy *  2 will give you meters along transect, going from South to North and/or West to East (transects are not perfectly aligned South-North).\n",
    "\n",
    "Data quality flags:</br>\n",
    "0: High quality;</br>\n",
    "1: Low quality with deviation to the averaged value larger than 15 cm;</br>\n",
    "2: Unreasonable data;</br>\n",
    "3: No data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3767844a-89ce-47db-af9d-75de180ba5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getRelElv(subsite: str, year:int, measMethod: str, \n",
    "              dataInput:str = 'DB',removeFlags=[2,3]):\n",
    "    \"\"\"Gets relative elevation measurement from permafrost calval DB.\n",
    "    subsite: Abbvr of subsite (HV, HVE, IC, SM)\n",
    "    measMethod: 'gnss' or 'level'\n",
    "    dataInputs: 'DB' or 'from_csv' if using a set of csv files that emulate\n",
    "                the DB\n",
    "    removeFlags: list of data flags for which the corresponding results will be\n",
    "                 removed. Flags are 0 - good data, 1 - data 15 cm out of mean,\n",
    "                 2 - data very far from mean and probably erroneous,\n",
    "                 3 - data missing. Default: [2,3]\n",
    "    \"\"\"\n",
    "    middate = datetime(year,7,15)\n",
    "    pts = pu.pointnames(subsite)\n",
    "\n",
    "    if dataInput == 'from_csv':\n",
    "        data = pd.read_csv('fielddata/measured_displacement.csv')\n",
    "        data['measurement_date'] = [datetime.strptime(i,'%Y-%m-%d') \n",
    "                                    for i in data['measurement_date']]\n",
    "\n",
    "    m1,m2 = [],[] #early/late summer measurement\n",
    "    date1,date2 = np.nan,np.nan\n",
    "    \n",
    "    for pt in pts:\n",
    "        querystr = f'point_id_keystr == \"{pt}\" and measurement_type == \"{measMethod}\"'\n",
    "        ptdata = data.query(querystr)\n",
    "        d1,d2 = pu.sortyeardate(ptdata,year,middate)\n",
    "        meas1, meas2 = np.nan,np.nan\n",
    "        if len(d1)>=1:\n",
    "            meas1 = d1.iloc[0]['relative_elevation_m']\n",
    "            date1 = pd.Timestamp(d1.iloc[0]['measurement_date']).to_pydatetime()\n",
    "            mflag = d1.iloc[0]['measurement_flag']\n",
    "            if mflag in removeFlags:\n",
    "                meas = np.nan\n",
    "        m1.append(meas1)\n",
    "        \n",
    "        if len(d2)>=1:\n",
    "            meas2 = d2.iloc[0]['relative_elevation_m']\n",
    "            date2 = pd.Timestamp(d2.iloc[0]['measurement_date']).to_pydatetime()\n",
    "            mflag = d2.iloc[0]['measurement_flag']\n",
    "            if mflag in removeFlags:\n",
    "                meas2 = np.nan\n",
    "        m2.append(meas2)\n",
    "    \n",
    "    return np.array(m1),np.array(m2),date1,date2,pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7eb0c-9d57-4350-99d8-06b81066f685",
   "metadata": {},
   "source": [
    "Regarding 2023, the transects for the site Happy Valley East were created in August 2023, and therefore subsidence measurements do not exist for that summer. At Slope Mountain, the GNSS measurements were not collected in June 2023, and therefore summer displacements only come from the surveying. In June 2024 neither level nor GNSS measurements were able to be taken at Slope Mountain.\n",
    "\n",
    "Now we can plot the field measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f18ff-8613-48e2-a0c9-963d75e518c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trdist = np.linspace(0,100,51)\n",
    "tnames = ['TA','TB','TC']\n",
    "for k,subsite in enumerate(fieldsites):\n",
    "    lv1,lv2,lvd1,lvd2,pts = getRelElv(subsite,year,'level',dataInput = 'from_csv')\n",
    "    gn1,gn2,gnd1,gnd2,__ = getRelElv(subsite,year,'gnss',dataInput = 'from_csv')\n",
    "    lvd,gnd = lv2-lv1,gn2-gn1\n",
    "    if pd.isnull(lvd1):\n",
    "        lvd1 = datetime(year,6,1)\n",
    "    if pd.isnull(lvd2):\n",
    "        lvd2 = datetime(year,9,1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,4.5))\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    d1str = lvd1.strftime('%Y-%m-%d')\n",
    "    d2str = lvd2.strftime('%Y-%m-%d')\n",
    "    fig.suptitle(f'{fieldsitenames[k]}\\n{d1str} to {d2str}')\n",
    "    for i in range(3):\n",
    "        axt = fig.add_subplot(3,2,1+i*2)   \n",
    "        plt.plot(trdist,lvd[i*51:(i+1)*51]*100,'.-',color='black',label='level')\n",
    "        plt.plot(trdist,gnd[i*51:(i+1)*51]*100,'x-',color='gray',label='GNSS')\n",
    "\n",
    "        axt.set_ylim(-18,5)\n",
    "        axt.set_xlim(-1,101)\n",
    "        axt.axhline(0,linestyle='--',color='k')\n",
    "        t=tnames[i]\n",
    "        axt.text(91,-28,t,fontsize=12)\n",
    "        \n",
    "        if i<2:\n",
    "            axt.set_xticks([])\n",
    "        if i==2:\n",
    "            if k!=0:\n",
    "                axt.legend()\n",
    "            axt.set_xlabel('Distance along transect (m)')\n",
    "            axt.set_ylabel('Displacement (cm)')\n",
    "        if k==0:\n",
    "            if i==0:\n",
    "                axt.legend(loc=3)\n",
    "\n",
    "        ax.plot(gnd*100,lvd*100,'.')\n",
    "\n",
    "    ax.axhline(0,linestyle='--',color='k')\n",
    "    ax.axvline(0,linestyle='--',color='k')\n",
    "    # ax.legend()\n",
    "    ax.set_xlim([-25,5])\n",
    "    ax.set_ylim([-25,5])\n",
    "    ax.set_xlabel('GNSS displacement (cm)')\n",
    "    ax.set_ylabel('Level displacement (cm)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f57bf-2e0d-4403-aed0-4e56693e01ff",
   "metadata": {},
   "source": [
    "### Save mean values\n",
    "\n",
    "We take the mean value across each 100 m site to make it comprable to the InSAR results. The mean values and standard deviations are saved into ```field_results.csv```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f8fc4-f20c-48df-9091-0635feb0802b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fielddisp = pd.DataFrame(columns = ['name','date1','date2','rel_change','stdev'])\n",
    "for k,subsite in enumerate(fieldsites):\n",
    "    lat,lon = fieldsitelocs[k]\n",
    "    lv1,lv2,lvd1,lvd2,pts = getRelElv(subsite,year,'level',dataInput = 'from_csv')\n",
    "    gn1,gn2,gnd1,gnd2,__ = getRelElv(subsite,year,'gnss',dataInput = 'from_csv')\n",
    "    lvd,gnd = lv2-lv1,gn2-gn1\n",
    "    if pd.isnull(lvd1):\n",
    "        lvd1 = datetime(year,6,1)\n",
    "    if pd.isnull(lvd2):\n",
    "        lvd2 = datetime(year,9,1)\n",
    "\n",
    "    ldisp,lstd = np.nanmean(lvd),np.nanstd(lvd)/np.sqrt(np.sum(~np.isnan(lvd)))\n",
    "    gdisp,gstd = np.nanmean(gnd),np.nanstd(gnd)/np.sqrt(np.sum(~np.isnan(gnd)))\n",
    "    tdisp = np.nanmean([ldisp,gdisp])\n",
    "\n",
    "    #get standard deviation between measurement types, propogate errors\n",
    "    #conditional used to avoid dividing by zero if there is no data\n",
    "    stdvec = np.array([lstd,gstd])\n",
    "    ntot = np.sum(~np.isnan(stdvec))\n",
    "    if ntot>0:\n",
    "        tstd = 1/ntot*np.sqrt(np.nansum(stdvec**2))\n",
    "    else:\n",
    "        tstd = np.nan\n",
    "\n",
    "    print(f'{subsite}')\n",
    "    print(f'Mean from leveling: {ldisp*100:.1f} +/- {lstd*100:.1f} cm')\n",
    "    print(f'Mean from GNSS:     {gdisp*100:.1f} +/- {gstd*100:.1f} cm')\n",
    "    print(f'Overall mean:       {tdisp*100:.1f} +/- {tstd*100:.1f} cm\\n')\n",
    "\n",
    "    \n",
    "    sitedata = [subsite,lvd1,lvd2,tdisp,tstd]\n",
    "    fielddisp.loc[k]=sitedata\n",
    "print('Displaying dataframe:')\n",
    "print(fielddisp)\n",
    "\n",
    "svfile = field_dir/'field_results.csv'\n",
    "print(f'\\n Saving data to {str(svfile)}')\n",
    "fielddisp.to_csv(svfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_earth_atbd",
   "language": "python",
   "name": "solid_earth_atbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
