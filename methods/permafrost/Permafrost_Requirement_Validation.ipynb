{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Workflow to Validate NISAR L2Permafrost Displacement Requirement\n",
    "\n",
    "**Code authored by:** Andrew Johnson, Simon Zwieback, Franz Meyer, Jie Chen</br>\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e250f0-bb27-4b5f-8271-91006349bfe9",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "\n",
    "[**Prep A. Environment Setup**](#permafrost_prep_a)\n",
    "\n",
    "[**Prep B. Data Staging**](#permafrost_prep_b)\n",
    "\n",
    "[**1. Generation of Interferogram stack**](#permafrost_infgs)\n",
    "\n",
    "[**2. Generation of time series from interferograms**](#permafrost_mintpy)\n",
    "- [2.1 Set up MintPy configuration file](#permafrost_mintpy_config)\n",
    "- [2.2 Load data into MintPy](#permafrost_mintpy_load)\n",
    "- [2.3 Validate/Modify interferogram network](#permafrost_mintpy_validate)\n",
    "- [2.4 Reference interferograms to common lat/lon](#permafrost_mintpy_reference)\n",
    "- [2.5 Invert for SBAS line-of-site timeseries](#permafrost_mintpy_invert)\n",
    "\n",
    "[**3. Optional Corrections**](#permafrost_correct)\n",
    "- [3.1 Troposphere correction](#permafrost_corect_troposphere)\n",
    "- [3.2 Phase deramping](#permafrost_correct_phase)\n",
    "- [3.3 Topographic residual correction](#permafrost_correct_topography)\n",
    "\n",
    "[**4. Validation method A: InSAR-only struction functions**](#permafrost_insar_validate)\n",
    "- [4.1 Use structure functions to identify pixel pairs](#permafrost_insar_structure)\n",
    "- [4.2 Evaluate displacements of pairs with respect to requirement](#permafrost_insar_evaluate)\n",
    "\n",
    "[**5. Validation method B: Comparison to ground truth displacements**](#permafrost_field_validate)\n",
    "- [5.1 Load field data](#permafrost_field_data)\n",
    "- [5.2 Prepare InSAR for field comparison](#permafrost_field_prepare)\n",
    "- [5.3 Re-run MintPy with field reference points](#permafrost_reference_point)\n",
    "- [5.4 Evaluate displacements with respect to requirement](#permafrost_field_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fe611-1ac0-47d3-98bf-838d5a413bd1",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<a id='permaforst_prep_a'></a>\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "#### Load Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d008b0-7433-49ef-8bbc-962d39444a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from mintpy import plot_network,view\n",
    "from mintpy.utils import readfile\n",
    "from solid_utils import permafrost_utils as pu\n",
    "from solid_utils.sampling import load_geo_utm, samp_pair,load_geo_utm\n",
    "from solid_utils.plotting import display_permafrost_validation \n",
    "from solid_utils.plotting import display_validation_table\n",
    "from solid_utils.saving import save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13365f02-7935-4e51-b2e0-93eab593130b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site = 'NorthSlopeEastD102'\n",
    "requirement = 'permafrost'\n",
    "dataset = 'Hyp3_S1'\n",
    "year = 2025\n",
    "start_directory = 'default'\n",
    "\n",
    "custom_sites = \"/home/jovyan/my_sites.txt\"  # Path to custom site metadata\n",
    "try:\n",
    "    with open(custom_sites, \"r\") as f:\n",
    "        sitedata = json.load(f)\n",
    "    site_info = sitedata[\"sites\"][site]\n",
    "except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "    raise RuntimeError(f\"Failed to load site metadata from {custom_sites}: {e}\")\n",
    "except KeyError:\n",
    "    raise ValueError(f\"Site ID '{site}' not found in {custom_sites}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5fa73-dd76-4d2e-83cd-453777e469f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# Set Directories ##########################################\n",
    "print('\\nCurrent directory:',os.getcwd())\n",
    "\n",
    "start_directory = Path(f'/scratch/nisar-st-calval-solidearth/permafrost')\n",
    "work_dir = os.path.join(start_directory,dataset,site,str(year))\n",
    "field_dir = os.path.join(start_directory,'fielddata')\n",
    "\n",
    "gunw_dir = os.path.join(work_dir,'products')\n",
    "mintpy_dir = os.path.join(work_dir,'MintPy')\n",
    "os.makedirs(mintpy_dir,exist_ok=True)\n",
    "print(\"   MintPy  dir:\", mintpy_dir)\n",
    "\n",
    "# # Change to Workdir   \n",
    "os.chdir(mintpy_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737979c-f9d2-4c55-bd0b-33fef3435752",
   "metadata": {},
   "source": [
    "<a id='permafrost_infgs'></a>\n",
    "# 1. Generation of interferogram stack\n",
    "\n",
    "The NISAR project will provide sets of fully coregistered ascending and descending unwrapped L2 interferograms (aka InSAR “stacks”) over regions of interest listed in the NISAR Solid Earth calval document. Prior to the launch of NISAR, we use interferograms generated by the Hybrid Pluggable Processing Pipeline (Hyp3) at the Alaska Satellite Facility (ASF) from Sentinel-1 SAR data. Hyp3 interfergram generation uses GAMMA and identifies overlapping Sentinel-1 bursts, and coregisters them using an iterative offset polynomial method and an Enhanced Spectral Diversity algorithm. Information about the Hyp3 inferferogram generation [can be found here](#https://hyp3-docs.asf.alaska.edu/guides/insar_product_guide/).\n",
    "\n",
    "Use the [Generating Hyp3 Interferograms](./Generate_Hyp3_Interferograms.ipynb) notebook to produce and download this data. We create interferogram stacks to cover a 96 day summer time period over on permafrost terrain to measure displacement when the surface is snow-free and traditionally experiencing subsidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81b3ee-f6fa-42c1-981b-282b1c0497a8",
   "metadata": {},
   "source": [
    "<a id='permafrost_mintpy'></a>\n",
    "# 2. Generation of time series from interferograms\n",
    "\n",
    "InSAR time series (i.e. the unfiltered displacement of each pixel vs. time) will be estimated from a processed InSAR stack using a variant of the small baseline subset (SBAS) approach. For this step, we use a time series inversion method of the Miami InSAR Time-series software in Python (MintPy) with 12 and 24 day interferogram pairs.\n",
    "\n",
    "Note: this code is currently set up to run on MintPy version 1.5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89886a4-2fd4-4da1-b5a6-03deb83f4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into mintpy, if not done already\n",
    "config_file = os.path.join(mintpy_dir,site + f'_{year}.cfg')\n",
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep load_data'\n",
    "process = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25de52-0f45-4f03-838d-36463e2cbec6",
   "metadata": {},
   "source": [
    "<a id='permafrost_mintpy_validate'></a>\n",
    "## 2.1 Validate/Modify Interferogram Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b16f1-7ea3-4979-a612-a7b728b7fe50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file = os.path.join(mintpy_dir,site + f'_{year}.cfg')\n",
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep modify_network'\n",
    "process = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0144b-6389-4bb3-9852-1720ed83953a",
   "metadata": {},
   "source": [
    "<a id='permafrost_mintpy_reference'></a>\n",
    "## 2.2 Reference interferograms to common Lat/Lon\n",
    "\n",
    "Note: The printed ```REF_LAT``` and ```REF_LON``` from this step will be the UTM y and x coordinates, respectively. ```REF_X``` and ```REF_Y``` are the j and i (column and row) indices of the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328e727-7bc2-4451-b9f6-8607bf04db6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep reference_point'\n",
    "process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "os.system('info.py inputs/ifgramStack.h5 | egrep \"REF_\"');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90e22b-e6f2-4425-8fe9-2ea7381a5ca7",
   "metadata": {},
   "source": [
    "<a id='permafrost_mintpy_invert'></a>\n",
    "## 2.3 Invert for SBAS Line-of-Sight Timeseries\n",
    "\n",
    "Run the network inversion to generate the timeseries file.\n",
    "\n",
    "Note: If run in OpenScienceLab, this step takes approximately 30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410c440-06ce-4565-bac3-a02c5f153fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep invert_network'\n",
    "process = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b919357-dab4-4e61-9c4c-f241e279e777",
   "metadata": {},
   "source": [
    "<a id='permafrost_correct'></a>\n",
    "# 3. Optional corrections\n",
    "\n",
    "Mintpy provides functionality for a number of standard corrections which might improve the accuracy of the timeseries inversion or displacement results. Several corrections are shown here:\n",
    "\n",
    "* Troposphere correction </br>\n",
    "* Deramping </br>\n",
    "* Topographic residual correction\n",
    "\n",
    "None of these corrections are currently applied in the analysis presented in this notebook, but the code here can easily be modified to add this functionality if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46829fbb-6d7a-4702-aaa6-881620ee5401",
   "metadata": {},
   "source": [
    "<a id='permafrost_correct_troposphere'></a>\n",
    "## 3.1 Trophosphere correction\n",
    "\n",
    "Atmospheric effects, especially moisture, can cause phase delays in the measured satellite signal. ERA5 reanalysis products provide information about atmospheric moisture and can be used to estimate the tropospheric phase delays. Performing this correction requires obtaining the ERA5 reanalysis products separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27027503-4513-4bf5-97b7-81b7b8a81d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_tropo_correction = False\n",
    "########################################################################\n",
    "'''\n",
    "REFERENCE : https://github.com/insarlab/pyaps#2-account-setup-for-era5\n",
    "Read Section 2 for ERA5 [link above] to create an account on the CDS website.\n",
    "'''\n",
    "\n",
    "if do_tropo_correction:\n",
    "    if not Use_Staged_Data and not os.path.exists(Path.home()/'.cdsapirc'):\n",
    "        print('NEEDED to download ERA5, \\\n",
    "        link: https://cds.climate.copernicus.eu/user/register')\n",
    "        UID = input('Please type your CDS_UID:')\n",
    "        CDS_API = input('Please type your CDS_API:')\n",
    "        \n",
    "        cds_tmp = '''url: https://cds.climate.copernicus.eu/api/v2\n",
    "        key: {UID}:{CDS_API}'''.format(UID=UID, CDS_API=CDS_API)\n",
    "        os.system('echo \"{cds_tmp}\" > ~/.cdsapirc; chmod 600 ~/.cdsapirc'\n",
    "            .format(cds_tmp = str(cds_tmp)))\n",
    "    \n",
    "    command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep \\\n",
    "    correct_troposphere'\n",
    "    process = subprocess.run(command, shell=True)\n",
    "    \n",
    "    # view.main(['inputs/ERA5.h5'])\n",
    "    timeseries_filename = 'timeseries_ERA5.h5'\n",
    "else:\n",
    "    timeseries_filename = 'timeseries.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f7bad-d66e-4b9e-b5b8-61719af7157e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The rest of the notebook is using the variable <code>timeseries_filename</code> as InSAR result. <b>Make sure <code>timeseries_filename</code> is set to the correct file</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c05662-be0b-467a-9c85-e0da83520ac5",
   "metadata": {},
   "source": [
    "<a id='permafrost_correct_phase'></a>\n",
    "## 3.2 Phase deramping\n",
    "\\[Mintpy provides this functionality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca01319-5d06-45cb-b38e-99b18f5acc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep deramp'\n",
    "process = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5108f-5a0f-445a-b50b-35302f151a0f",
   "metadata": {},
   "source": [
    "<a id='permafrost_correct_topography'></a>\n",
    "## 3.3 Topographic residual correction\n",
    "\\[Mintpy provides this functionality\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043acd7-4ab4-47cd-87c6-d1e2e50580eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep correct_topography'\n",
    "process = subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085d640-9434-426b-93f3-e0f3f053dd1f",
   "metadata": {},
   "source": [
    "<!-- <a id='permafrost_insar_validate'></a>\n",
    "# 4. Validation Method 1: Comparison to observed field data\n",
    "\n",
    "The NISAR permafrost validation requirement states that at least 80% of the time, the difference in surface displacement for two given points over 90 days should be no greater than $4(1+\\sqrt{\\text{L}})$ mm for points of L km apart, with $\\text{L} \\leq 50$ km.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eff19-7abb-45a1-93be-37f686a4c66a",
   "metadata": {},
   "source": [
    "<a id='permafrost_field_validate'></a>\n",
    "# 4. Validation Method 1: Comparison to ground truth displacements\n",
    "\n",
    "![Survey at Happy Valley East](HappyValleyEast_level.png)\n",
    "Photo: Level survey being conducted at Happy Valley East in Sept., 2025. Credit: Andrew Johnson\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- We can compare the Interferometric displacements to the measured displacements at the field sites. The locations of the field sites are as follows (XY values in UTM, EPSG 32605):\n",
    "\n",
    "Happy Valley (HV): x=664946, y=7677215</br>\n",
    "Happy Valley East (HVE): x=665175, y=7677290</br>\n",
    "Ice Cut (IC): x=666290, y=7664601</br>\n",
    "Slope Mountain (SM): x=664156, y=7629999</br> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d846ac-f1b1-4c50-9ff3-5dd5c0de943b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pointnames = ['HV','HVE','IC','SM']\n",
    "pointlocs = [[1114,3285],[1113,3288],[1272,3302],[1705,3275]]\n",
    "pointlocsxy = [[664946,7677215],[665175,7677290],[666290,7664601],[664156,7629999]]\n",
    "pointsubsetlocs = [[119, 287], [118, 290], [277, 304], [710, 277]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce2ac2-144f-4ce9-a295-17b8e92c086a",
   "metadata": {},
   "source": [
    "<a id='permafrost_field_data'></a>\n",
    "## 4.1 Load field data\n",
    "\n",
    "Field observations of summer subsidence were taken for several areas of interest on the North Slope of Alaska, along the Dalton Highway. The ground in this area is snow-free for approximately three months each summer, usually from late May to late August. Measurements from leveling (surveying) and GNSS were taken at the beginning and end of this summer time period. Each field area of interest has 153 sampled points over a 100 m square on the ground.\n",
    "\n",
    "The end result of these observations are direct measurements of the surface subsidence which can be compared with the satellite-InSAR derived surface displacement product. See the accompanying notebook [Permafrost_fielddata](./Permafrost_fielddata.ipynb) for details. That notebook produces a small file called ```field_results.csv```, which is an input for this validation.\n",
    "\n",
    "We create an array for the relative displacement of each field site relative to each other site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854b3e7-14b8-4060-bbae-003a88f09026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load in observed data\n",
    "fielddata_file = Path(work_dir)/'field_results.csv'\n",
    "\n",
    "obsdata = pd.read_csv(fielddata_file) #ground truth observations\n",
    "obsdisp = obsdata['rel_change'][:]\n",
    "obsstd = obsdata['stdev'][:]\n",
    "obsdiff = np.zeros((len(obsdisp),len(obsdisp)))\n",
    "obsdiffstd = np.zeros_like(obsdiff)\n",
    "fielddates = []\n",
    "for i in range(len(obsdisp)):\n",
    "    for j in range(len(obsdisp)):\n",
    "        obsdiff[i,j] = obsdisp[i]-obsdisp[j]\n",
    "\n",
    "        #use sum of squares to propagate error of subtracted measurements\n",
    "        obsdiffstd[i,j] = np.sqrt(obsstd[i]**2+obsstd[j]**2)\n",
    "    \n",
    "    date1 = dt.strptime(str(obsdata['date1'][i]),'%Y-%m-%d')\n",
    "    date2 = dt.strptime(str(obsdata['date2'][i]),'%Y-%m-%d')\n",
    "    fielddates.append([date1,date2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165f131-8e6b-47e2-a1e5-d7e5ea92e59b",
   "metadata": {},
   "source": [
    "<a id='permafrost_field_prepare'></a>\n",
    "## 4.2 Prepare InSAR for field comparison\n",
    "\n",
    "\n",
    "In order to perform double differencing of InSAR displacements in a way that will be comparable to the field observations, we run the mintpy inversion several times, with the reference point set to a different field validation site each time, and also using a spline fitting function to fit the InSAR timeseries to the exact dates of the field measurements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ab2d3-43b3-40b3-aceb-b87c5d89594e",
   "metadata": {},
   "source": [
    "### 4.2.1 Perform timeseries reconstruction\n",
    "\n",
    "The displacement time series from mintpy is reconstruted here by spline-fitting it the time series to a set of basis functions, following Zwieback et al. (2020). The basis functions represent typical summer permafrost surface subsidence patterns, due melting ice in the active layer. The spline fitting reconstruction both reduces the noise from individual acquisitions, and also allows us to identify the InSAR displacement for arbitrary dates within the period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af50d9-daa5-4afa-9213-d7fcc73fb637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts = pu.Timeseries.from_file(fn = Path(mintpy_dir)/timeseries_filename)\n",
    "sm = pu.SplineModel(dates_o=ts.dates)\n",
    "\n",
    "#perform the reconstruction\n",
    "ts_rec = sm.reconstruct(timeseries=ts)\n",
    "\n",
    "# plot basis functions\n",
    "pu.plot_basis_functions(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081fd52-aeb2-404c-8c32-c207b06c159e",
   "metadata": {},
   "source": [
    "Now we will demonstrate the reconstuction at a single point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c82a84-3540-4a7c-b5f3-1b5da0f30049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipt,jpt = 500,200\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(y=0,linestyle='--',color='k')\n",
    "plt.plot(ts.dates,ts.timeseries[:,ipt,jpt],'.',markersize=12,label='data')\n",
    "plt.plot(ts_rec.dates,ts_rec.timeseries[:,ipt,jpt],'.-',\n",
    "         markersize=8,label='reconstruction')\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a17b9-d4ad-4497-b4ef-29d20a3acfd1",
   "metadata": {},
   "source": [
    "Additionally we can show the summer time displacement across the entire region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe36477-3207-42e4-804a-029fefd29178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The fieldsites of Happy Valley and Happy Valley East are too close to plot separately in this step.\n",
    "labelpoints = [[119, 287], [277, 304], [710, 277]]\n",
    "labelpointnames = ['HV/HVE','IC','SM']\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(ts_rec.timeseries[-1]-ts_rec.timeseries[0],\n",
    "           vmin=-0.10,vmax=0.10,cmap='RdBu')\n",
    "plt.colorbar()\n",
    "for k,name in enumerate(labelpointnames):\n",
    "    pt = labelpoints[k]\n",
    "    plt.plot(pt[1],pt[0],'*',markersize=8,color='k')\n",
    "    plt.text(pt[1]+20,pt[0]+10,name,fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca46534-2c2b-4bcd-a621-60d33fa33674",
   "metadata": {},
   "source": [
    "<a id='permafrost_insar_diff'></a>\n",
    "### 4.3 Compare InSAR and field displacement results\n",
    "\n",
    "First we compare the InSAR displacement between the field sites for the given field observations dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a892c1c-ebb9-4569-833c-fd3613482386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Retrieve InSAR displacment differences between points\n",
    "locdisp = []\n",
    "for k,name in enumerate(pointnames):\n",
    "    ts_rec = sm.reconstruct(timeseries=ts,dates_r=fielddates[k])\n",
    "    ipt,jpt = pointsubsetlocs[k]\n",
    "    locdisp.append(ts_rec.timeseries[-1,ipt,jpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587409a-d070-4339-b4f6-2872d1d8ef9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next we compare the double difference of displacement between each subsite pair from InSAR and field data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc827d0-4ab8-4375-a4fa-d84facc56daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__,atrib = readfile.read(Path(mintpy_dir)/timeseries_filename) \n",
    "xst = float(atrib['X_STEP'])\n",
    "yst = float(atrib['Y_STEP'])\n",
    "\n",
    "dispdiff = []\n",
    "obsdiff = []\n",
    "obserr = []\n",
    "ddf = []\n",
    "dist = []\n",
    "\n",
    "locvec = locdisp\n",
    "loclen = len(locdisp)\n",
    "\n",
    "for k in range(loclen):\n",
    "    iref,jref = pointsubsetlocs[k]\n",
    "    for l in range(k+1,loclen):    \n",
    "        ipt,jpt = pointsubsetlocs[l]\n",
    "        dispdiff.append(locvec[k]-locvec[l]) #insar displacement difference\n",
    "        obsdiff.append(obsdisp[k]-obsdisp[l]) #field data displacement difference\n",
    "        obserr.append(np.sqrt(obsstd[k]**2+obsstd[l]**2))\n",
    "        ddf.append(np.abs(np.abs(dispdiff[-1])-np.abs(obsdiff[-1])))\n",
    "        dist.append(np.sqrt(((iref-ipt)*yst)**2+((jref-jpt)*xst)**2)/1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31911dc9-dd68-4b83-95d8-345889454f40",
   "metadata": {},
   "source": [
    "<a id='permafrost_field_evaluate'></a> \n",
    "## 4.4 Evaluate displacements to NISAR permafrost requirement\n",
    "\n",
    "### 4.4.1 Compute requirement validation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fcd3c-cc61-438a-bcb9-5636502cc495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddf_cm = np.array(ddf)*100               #double difference in cm\n",
    "obserr_cm = np.array(obserr)*100         #observation error in cm\n",
    "dist = np.array(dist)                 #distance (in km)\n",
    "reqvec = 4*(1+np.sqrt(dist))/10       #requirement in cm\n",
    "\n",
    "#remove HVE in 2023, and SM in 2024\n",
    "sitemask = np.array([1,1,1,1,1,1],dtype='bool')\n",
    "if year == 2023:\n",
    "    sitemask = np.array([0, 1, 1, 0, 0, 1],dtype='bool')\n",
    "if year == 2024:\n",
    "    sitemask = np.array([1, 1, 0, 1, 0, 0],dtype='bool')\n",
    "ddf_cm = ddf_cm[sitemask]\n",
    "obserr_cm = obserr_cm[sitemask]\n",
    "dist = dist[sitemask]\n",
    "reqvec = reqvec[sitemask]\n",
    "\n",
    "succvec = np.array(ddf_cm <= reqvec)\n",
    "succerr = np.array(ddf_cm-obserr_cm <= reqvec)\n",
    "req_met_rate = np.sum(succvec)/len(succvec)\n",
    "req_within_MOE = np.sum(succerr)/len(succerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc17fb4-eda7-43b5-9780-4fc99841b2f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "## 4.4.2 Visualize validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696528b-dae4-45e1-8271-063e16cd1b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "req_thresh = 0.8\n",
    "val, val_MOE = False,False\n",
    "val_str, val_MOE_str = 'FAILED','FAILED'\n",
    "if req_met_rate>=req_thresh:\n",
    "    val = True\n",
    "    val_str = 'PASSED'\n",
    "if req_within_MOE >= req_thresh:\n",
    "    val_MOE = True\n",
    "    val_MOE_str='PASSED'\n",
    "\n",
    "\n",
    "print(f\"Percent of double differences which meet the requirement: \\\n",
    "{req_met_rate*100:.1f}%, validation: {val_str}\")\n",
    "print(f\"Percent of double differences within margin of error of requirement: \\\n",
    "{req_within_MOE*100:.1f}%, validation: {val_MOE_str}\")\n",
    "\n",
    "dist_th = np.linspace(0.1,50,100)  # distances for evaluation\n",
    "acpt_error = 4*(1+np.sqrt(dist_th))  # permafrost threshold in mm\n",
    "acpt_error_cm = acpt_error/10.\n",
    "start_date = np.min(fielddates)\n",
    "end_date = np.max(fielddates)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "plt.scatter(dist,ddf_cm,label='|$D_{obs} - D_{InSAR}|$ for pair')\n",
    "plt.plot(dist_th, acpt_error_cm, 'r',label='Permafrost requirement')\n",
    "# ax.set_xscale('log')\n",
    "plt.ylim(0,7)\n",
    "plt.xlim(0,50)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(f\"Double-Difference Residuals \\n Date range \\\n",
    "{start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} \\n InSAR\\\n",
    "and surveying/GNSS simple subtraction displacement\")\n",
    "plt.xlabel(\"Distance (km)\")\n",
    "plt.ylabel(\"Amplitude of Double-Differenced Displacement Residual (cm)\")\n",
    "plt.errorbar(dist,ddf_cm,yerr=obserr_cm,ls='none',capsize=5)\n",
    "\n",
    "\n",
    "# Add legend with validation info \n",
    "textstr = f'Permafrost requirement\\n'\n",
    "textstr += f'Site: NorthSlopeEast\\n'\n",
    "# if validation.loc['Total']['success_fail']:\n",
    "if val:\n",
    "    validation_color = '#239d23'\n",
    "else:\n",
    "    validation_color = '#bc2e2e'\n",
    "\n",
    "\n",
    "props = {**{'facecolor':'none', 'edgecolor':'none'}}\n",
    "ax.text(37, 6.15, textstr, fontsize=12)#, bbox=props)\n",
    "ax.text(39, 6.05,  val_str, fontsize=16, weight='bold')\n",
    "\n",
    "rect = patches.Rectangle((36.5, 5.95), 12.5, 0.9,\n",
    "                       linewidth=1, edgecolor='black',\n",
    "                       facecolor=validation_color)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ebd91-44e5-45a6-9194-cf61d247d8a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4.3 Prepare validation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72df4f3-75f6-4cce-91ce-5ebc7140510b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "req_thresh = 0.8\n",
    "\n",
    "count = np.array([np.size(i) for i in ddf_cm])\n",
    "passed = np.array([np.sum(i) for i in succvec])\n",
    "passed_within_MOE = np.array([np.sum(i) for i in succerr])\n",
    "success = passed/count >= req_thresh\n",
    "success_within_MOE = passed_within_MOE/count >= req_thresh\n",
    "\n",
    "columns = ['distance[km]', 'count', 'passed',\n",
    "           'within_MOE', 'success', 'success_within_MOE']\n",
    "\n",
    "validation = pd.DataFrame(np.vstack([dist,\n",
    "                                     count,\n",
    "                                     passed,\n",
    "                                     passed_within_MOE,\n",
    "                                     success,\n",
    "                                     success_within_MOE],dtype=object).T,\n",
    "                                     columns = columns)\n",
    "\n",
    "sumrow = ['Total',\n",
    "           np.sum(count),\n",
    "           np.sum(passed),\n",
    "           np.sum(passed_within_MOE),\n",
    "           np.sum(passed)/np.sum(count) >= req_thresh,\n",
    "           np.sum(passed_within_MOE)/np.sum(count) >= req_thresh]\n",
    "validation = pd.concat([validation, pd.DataFrame([sumrow],columns = columns)],ignore_index=True)\n",
    "if validation.loc[validation.index[-1]]['success']:\n",
    "    print(\"This displacement dataset passes the requirement.\")\n",
    "else:\n",
    "    print(\"This displacement dataset does not pass the requirement.\")\n",
    "if validation.loc[validation.index[-1]]['success_within_MOE']:\n",
    "    print(\"This displacement dataset passes the requirement within the field measurement margin of error.\")\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70523831-9dc7-46de-86c1-6863bc76eb67",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Validation Method 1: success for a baseline distance bin occurs when the percentage of residuals within the requirement success threshold is >0.8\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac4b93-056e-4ea1-bf9a-e2abcdb25ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4.4 Save Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37baa020-0c74-4163-af01-5bfe3cb0b103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Method 1 results to file\n",
    "run_date = dt.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_fldr = f\"{run_date}-Permafrost-Method1\"\n",
    "# save_dir = os.path.join(mintpy_dir, save_fldr)\n",
    "save_dir = str(Path.home()/'stash') #set your own location\n",
    "\n",
    "validation_fig_method1 = fig\n",
    "validation_table_method1 = validation\n",
    "\n",
    "save_params = {\n",
    "    'save_dir': save_dir,\n",
    "    'run_date': run_date,\n",
    "    'requirement': \"Permafrost\",\n",
    "    'site': site,\n",
    "    'method': \"1\",\n",
    "    'sitedata': site_info,\n",
    "    'gnss_insar_figs': [],\n",
    "    'validation_figs': [validation_fig_method1],\n",
    "    'validation_table': validation_table_method1,\n",
    "    'ts_functions': None,\n",
    "}\n",
    "save_results(**save_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8c61d-4935-49ee-a661-6fe588f8f8f6",
   "metadata": {},
   "source": [
    "<a id='permafrost_insar_validate'></a>\n",
    "# 5. Validation Method 2: InSAR-only structure fucntions\n",
    "\n",
    "The NISAR permafrost validation requirement states that at least 80% of the time, the difference in surface displacement for two given points over 90 days should be no greater than $4(1+\\sqrt{\\text{L}})$ mm for points of L km apart, with $\\text{L} \\leq 50$ km.\n",
    "\n",
    "The surface deformation across tundra permafrost will vary spatially due to multiple mechanisms, including soil type, excess surface ice, and local topography and climate. Variability occurs at spatial scales from centimeters to tens of kilometers. Nonetheless, we will evaluate the differences in surface displacement relative to the validation requirement using the InSAR signal alone over this terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d32f3-656e-4133-b2e8-374ed70defe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Permafrost requirements:\n",
    "dist_th = np.linspace(0.1,50,100)  # distances for evaluation (km)\n",
    "acpt_error = 4*(1+np.sqrt(dist_th))  # permafrost threshold in mm, for dist in km\n",
    "acpt_error_cm = acpt_error/10.  #cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a624d4f-df59-46d6-8969-f14e2d4a60e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show displacements at end of the timeseries\n",
    "if 'timeseries_filename' not in locals():\n",
    "    timeseries_filename = 'timeseries.h5'\n",
    "\n",
    "with h5py.File(Path(mintpy_dir)/timeseries_filename, 'r') as f:\n",
    "    dispmap = np.array(f['timeseries'][-1])*100\n",
    "\n",
    "vmax = np.nanmax(np.abs(dispmap))\n",
    "plt.figure()\n",
    "plt.imshow(dispmap,vmin=-vmax,vmax=vmax,cmap='RdBu')\n",
    "plt.colorbar(label='96 day displacement (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c472a-ab64-47d4-96ec-27eaa7a1dfef",
   "metadata": {},
   "source": [
    "<a id='permafrost_insar_structure'></a>\n",
    "##  5.1 Use structure functions to identify pixel pairs\n",
    "\n",
    "We sample a large set of pixel pairs to compare relative displacements with. We use a water mask from the Hyp3 processing to mask out locations to not use. Information about how that water mask is developed can [be found here](https://storymaps.arcgis.com/stories/485916be1b1d46889aa436794b5633cb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a677f-901e-49c1-a027-855795c4a0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__,atrib = readfile.read(Path(mintpy_dir)/timeseries_filename)\n",
    "\n",
    "X0,Y0 = load_geo_utm(atrib)\n",
    "X0_2d,Y0_2d = np.meshgrid(X0,Y0)\n",
    "\n",
    "M2dist = []; rel_measure = []\n",
    "\n",
    "tsmap = dispmap\n",
    "tsmap[tsmap==0]=np.nan\n",
    "\n",
    "# wmask = pu.get_watermask(Path(gunw_dir))\n",
    "with h5py.File(Path(mintpy_dir)/'waterMask.h5') as data:\n",
    "    wmask = data['waterMask'][:]\n",
    "tsmap[wmask==0]=np.nan\n",
    "\n",
    "#deramping will remove linear spatial trends in the displacement data.\n",
    "#Currently disabled\n",
    "dist_i, rel_measure_i = samp_pair(X0_2d,Y0_2d,tsmap,num_samples=1000000,deramp=False)\n",
    "\n",
    "M2dist.append(dist_i)             #distance of pair, in m\n",
    "rel_measure.append(rel_measure_i) #relative displacement of pair, in cm \n",
    "    \n",
    "M2dist,rel_measure = np.array(M2dist),np.array(rel_measure)\n",
    "\n",
    "#use only pixel pairs within 50 km\n",
    "rel_measure = rel_measure[M2dist<=50e3]\n",
    "M2dist=M2dist[M2dist<=50e3]\n",
    "\n",
    "M2km = [i/1e3 for i in M2dist]  #convert distance to km\n",
    "rmcm = [i for i in rel_measure] #relative measure in cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[9, 5.5])\n",
    "img1 = ax.hist(M2km, bins=100)\n",
    "ax.set_title(f\"Histogram of distance\")\n",
    "ax.set_xlabel(r'Distance ($km$)')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[9, 5.5])\n",
    "img1 = ax.hist(rmcm, bins=100)\n",
    "ax.set_title(f\"Histogram of Relative Measurement\")\n",
    "ax.set_xlabel(r'Relative Measurement ($cm$)')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe2464-e4f4-4dcd-bcaf-5a8b2732039b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = dt.strptime(atrib['START_DATE'], '%Y%m%d')\n",
    "end_date = dt.strptime(atrib['END_DATE'], '%Y%m%d')\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Define requirement\n",
    "permafrost_threshold_rqmt = 4  # mm/yr\n",
    "permafrost_distance_rqmt = [0.1, 50.0]  # km\n",
    "\n",
    "# Validation parameters\n",
    "n_bins = 10\n",
    "# threshold = 0.683  \n",
    "threshold = 0.8\n",
    "\n",
    "pair_distance = np.array([i/1e3 for i in dist_i])\n",
    "pair_difference = np.array([i*10 for i in rel_measure_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe837b49-80d2-40b7-80cc-a19e3fb6fd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_table,fig = display_permafrost_validation(pair_distance, # binned distance for point\n",
    "                        pair_difference, # binned relative velocities mm/yr\n",
    "                        site,\n",
    "                        start_str,\n",
    "                        end_str,\n",
    "                        requirement=permafrost_threshold_rqmt,\n",
    "                        req_dist_fcn=True,\n",
    "                        distance_rqmt = permafrost_distance_rqmt,  # [0.1, 50] km\n",
    "                        n_bins=n_bins,                  # number of bins, to collect statistics \n",
    "                        threshold=threshold,             \n",
    "                        sensor='Sentinel-1',            # sensor that is validated, Sentinel-1 or NISAR\n",
    "                        validation_type='permafrost',\n",
    "                        validation_data='Field meas')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d7949-39fd-4204-a8de-e2092d52fcd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "req_dist_fcn = True\n",
    "reqval = 4\n",
    "pair_req_met = np.array(pair_difference < reqval*(1+float(req_dist_fcn)*\n",
    "                                                  np.sqrt(pair_distance)))\n",
    "pair_req_met[np.isnan(pair_difference)]=np.nan\n",
    "df = pd.DataFrame(np.vstack([pair_distance,\n",
    "                            pair_difference,\n",
    "                            pair_req_met]).T,\n",
    "                            columns=['distance', 'double_diff','req_met'])\n",
    "\n",
    "# remove nans\n",
    "df_nonan = df.dropna(subset=['double_diff'])\n",
    "bins = np.linspace(*permafrost_distance_rqmt, num=n_bins+1)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "binned_df = df_nonan.groupby(pd.cut(df_nonan['distance'], bins),\n",
    "                            observed=False)[['req_met']]\n",
    "\n",
    "# get binned validation table \n",
    "bin_req = reqval*(1+float(req_dist_fcn)*np.sqrt(bin_centers))\n",
    "validation = pd.DataFrame([])\n",
    "validation['total_count[#]'] = binned_df.apply(lambda x: np.ma.masked_invalid(x)\n",
    "    .count())\n",
    "validation['passed_req.[#]'] = binned_df.apply(lambda x: np.count_nonzero(x))\n",
    "\n",
    "# Add total at the end\n",
    "validation = pd.concat([validation, pd.DataFrame(validation.sum(axis=0)).T])\n",
    "validation['passed_pc'] = validation['passed_req.[#]'] / validation['total_count[#]']\n",
    "validation['success_fail'] = validation['passed_pc'] > threshold\n",
    "validation.index.name = 'distance[km]'\n",
    "# Rename last row\n",
    "validation.rename({validation.iloc[-1].name:'Total'}, inplace=True)\n",
    "if validation.loc[validation.index[-1]]['success_fail']:\n",
    "    print(\"This displacement dataset passes the requirement.\")\n",
    "else:\n",
    "    print(\"This displacement dataset does not pass the requirement.\")\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a806207-7f08-4d8e-ba6c-aefcf60acfd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Validation Method 1: success for a baseline distance bin occurs when the percentage of residuals within the requirement success threshold is >0.8\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7dc97-53a6-4d09-91ac-eae6f65dacf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Method 2 results to file\n",
    "run_date = dt.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_fldr = f\"{run_date}-Permafrost-Method2\"\n",
    "save_dir = str(Path.home()/'stash') #set your own location\n",
    "\n",
    "validation_fig_method2 = fig\n",
    "validation_table_method2 = validation\n",
    "\n",
    "save_params = {\n",
    "    'save_dir': save_dir,\n",
    "    'run_date': run_date,\n",
    "    'requirement': \"Permafrost\",\n",
    "    'site': site,\n",
    "    'method': \"2\",\n",
    "    'sitedata': site_info,\n",
    "    'gnss_insar_figs': [],\n",
    "    'validation_figs': [validation_fig_method2],\n",
    "    'validation_table': validation_table_method2,\n",
    "    'ts_functions': None,\n",
    "}\n",
    "save_results(**save_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361fd78-30ad-4070-af0b-2604c71b6a3b",
   "metadata": {},
   "source": [
    "<a id='permafrost_references'></a>\n",
    "### References\n",
    "\n",
    "Zwieback, Simon, and Franz J. Meyer. \"Top-of-permafrost ground ice indicated by remotely sensed late-season subsidence.\" *The Cryosphere* 15 (2021): 2041-2055."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_earth_atbd",
   "language": "python",
   "name": "solid_earth_atbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
