{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a523400",
   "metadata": {},
   "source": [
    "<font size=\"1.5\">Copyright 2021, by the California Institute of Technology. ALL RIGHTS RESERVED. United States Government sponsorship acknowledged. Any commercial use must be negotiated with the Office of Technology Transfer at the California Institute of Technology.\n",
    "\n",
    "<font size=\"1.5\">This software may be subject to U.S. export control laws and regulations. By accepting this document, the user agrees to comply with all applicable U.S. export laws and regulations. User has the responsibility to obtain export licenses, or other export authority as may be required, before exporting such information to foreign countries or providing access to foreign persons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7927b8",
   "metadata": {},
   "source": [
    "# UAVSAR SLC stack processor\n",
    "\n",
    "<font size=\"3\">The notebook uses functions from ISCE StripmapStack and some additional functionalities in uavsar_utils folder to create Interferograms from SLC data. \n",
    "\n",
    "<font size=\"3\">Currently there is no support to automatically fetch the data. The users are required to copy the download urls from the [UAVSAR webpage](https://uavsar.jpl.nasa.gov/) into a text file locally. \n",
    "- If multiple segments exists, download urls for all the segments are needed.\n",
    "- The notebook reuires ISCE environment. (The last three cells require ISCE + MintPy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7906b-5d95-4e47-90c9-5b175fd2c15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import shelve\n",
    "import isce\n",
    "import isceobj\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "n_processes = 4 #int(multiprocessing.cpu_count()) - 2;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ffa52",
   "metadata": {},
   "source": [
    "## Add the required paths\n",
    "<font size=\"3\">Add path to the ISCE stripmapStack directory and the uavsar_utils directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd0ddd-2d0b-443e-b1ac-93205d37881c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the path of the ISCE base dir\n",
    "env_str = os.popen(\"conda env list | grep '/isce$' | awk '{print $NF}'\")\n",
    "isce_base_dir = env_str.read().strip();\n",
    "isce2_share_dir = f\"{isce_base_dir}/share/isce2\";\n",
    "\n",
    "# now add stripmapStack contrib directory to PATH \n",
    "stripmapStack_dir = f\"{isce2_share_dir}/stripmapStack\";\n",
    "# add UAVSAR functionalities to the path\n",
    "uavsar_utils_dir = '/home/jovyan/atbd-se-development/uavsar_utils'\n",
    "os.environ['PATH'] = f\"{uavsar_utils_dir}:{stripmapStack_dir}:{os.environ['PATH']}\"\n",
    "os.environ['ATBD'] = '/home/jovyan/atbd-se-development/'\n",
    "sys.path.append(os.environ['ATBD'])\n",
    "!export OMP_NUM_THREADS=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3620ae-3ed7-4af9-83d6-1d84fcd6e8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import insar functions. \n",
    "try:\n",
    "    from uavsar_utils.insar import ImageReader, Interferogram, correlation\n",
    "except:\n",
    "    print('Add uavsar_utils directory to pythonpath')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49e135-39a8-48a0-98a3-55f77f932c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_cmd(cmd):\n",
    "    print(\"Command: {}\".format(cmd))\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Command failed with error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a2ebde-05ea-416c-80aa-99c81d1da6e7",
   "metadata": {},
   "source": [
    "## Place all your inputs here. \n",
    "1. Point to your scratch directory or where you would process the data\n",
    "2. Give a folder name for the processing. \n",
    "3. Specify number of looks and number of connections per SLC.\n",
    "4. A bounding box is required to download the DEM. If not given will be calculated later from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462ccd2-9968-4846-9e50-b5e28f56845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_dir = '/scratch/bvarugu'; #define your scratch dir\n",
    "track_name = 'track_14003' #define the UAVSAR directory name\n",
    "segments = [1,2,3,4]; #define the SLC segments; Used for concatenation\n",
    "#reference_date = #input a reference date if not the first date will be considered reference date\n",
    "\n",
    "rlks = 3 #define range looks\n",
    "alks = 12  #define azimuth looks\n",
    "numConnections = 2 #define number of interferogram pairs to be made with each SLC similar to ISCE\n",
    "#bbox = '35 37 -122 -120' #Bounding box for DEM download #selected based on Northern San Andreas\n",
    "\n",
    "out_dir = os.path.join(scratch_dir,track_name);\n",
    "os.makedirs(out_dir, exist_ok=True);\n",
    "download_dir= os.path.join(out_dir,'download');\n",
    "os.makedirs(download_dir, exist_ok=True);\n",
    "os.chdir(download_dir);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae609e3",
   "metadata": {},
   "source": [
    "## Write the download links\n",
    "- Create a file named download_links.sh in the download folder and copy all your links in it. UAVSAR webpage has 'wget' populated infront of the links already.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d01f4e-a1e8-42ca-88eb-0ea8da4a911a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#copy the links from UAVSAR webpage into a file in the download dir named download_links.sh\n",
    "#this cell shall be updated if a better method of downloading UAVSAR data is available\n",
    "print('Downloading UAVSAR SLCs using wget links')\n",
    "!sh download_links.sh > download_log\n",
    "!rm *.ann.*\n",
    "!rm *.dop.*\n",
    "os.chdir(out_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699307cd",
   "metadata": {},
   "source": [
    "## Create SLC directory for  one/multiple SLC segments\n",
    "- A directory for each segment (Ex:SLC_seg1) is created. If only one segment then SLC directory will be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fecfc3-ca56-4a2f-bac9-903597a8128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SLC directory\n",
    "dop_file = glob.glob(os.path.join(download_dir, '*.dop'))[0];\n",
    "\n",
    "if len(segments)>1:\n",
    "    print('Multiple Segments exist. Creating multiple SLC segments directories!')\n",
    "    for i in range(len(segments)):\n",
    "        slc_seg_dir = 'SLC_seg{}'.format(segments[i]);\n",
    "        cmd = 'prepareUAVSAR_coregStack.py -i {} -d {} -o {} -s {}'.format(download_dir,dop_file,slc_seg_dir,segments[i]);\n",
    "        print(cmd);\n",
    "        os.system(cmd);\n",
    "        if i< len(segments)-1:\n",
    "            cmd = 'cp {}/*/*.ann {}'.format(slc_seg_dir,download_dir);\n",
    "            print(cmd);\n",
    "            os.system(cmd);\n",
    "    slc_dir = os.path.join(out_dir,'SLC_seg{}'.format(segments[0])); \n",
    "else:\n",
    "    print('Procesing only One Segment. No Concatenation')\n",
    "    slc_dir = os.path.join(out_dir,'SLC');\n",
    "    cmd = 'prepareUAVSAR_coregStack.py -i {} -d {} -o {} -s {}'.format(download_dir,dop_file,slc_dir,segments[0]);\n",
    "    os.system(cmd);\n",
    "\n",
    "print('SLC directory:',slc_dir);\n",
    "dateList = sorted(os.listdir(slc_dir));\n",
    "print('SLC dates:',dateList);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5562bac",
   "metadata": {},
   "source": [
    "### Give a reference data if not the first data will be considered reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c303b43-7525-4696-af35-74522de403a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slc_dir = os.path.join(out_dir,'SLC_seg{}'.format(segments[0])); \n",
    "try:\n",
    "    reference_date\n",
    "except:\n",
    "    reference_date=sorted(os.listdir(slc_dir))[0];\n",
    "print('Reference date for Meta data:',reference_date);\n",
    "reference_slc_dir = os.path.join(slc_dir,reference_date);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754ac39",
   "metadata": {},
   "source": [
    "## Read Metadata from the reference SLC\n",
    "\n",
    "- Here SLC meatadata is loaded into a dictionary variable to query for samples (columns), rows and bounding box for DEM.Each annotation file contains the info for all the segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ff7a5-9a27-4ae7-961f-4dcbfb75a790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read necessary info from the UAVSAR annotation file. Each annotation file contains the info for all the segments.\n",
    "def read_uavsar_ann_file(ann_file_path):\n",
    "    '''read UAVSAR ann file as a dict to query for rows, columns info '''\n",
    "    result_dict = {}\n",
    "    with open(ann_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip any leading/trailing whitespace and skip empty lines\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(';'):\n",
    "                continue\n",
    "            \n",
    "            # Split the line into key and value using '=' as the separator\n",
    "            if '=' in line:\n",
    "                key, value = line.split('=', 1);\n",
    "                key = key.split('(')[0].strip()\n",
    "                value = value.split(';')[0].strip()\n",
    "                result_dict[key.strip()] = value.strip()\n",
    "    \n",
    "    return result_dict\n",
    "ann_file_path = glob.glob(os.path.join(reference_slc_dir, '*.ann'))[0];\n",
    "slc_info_dict = read_uavsar_ann_file(ann_file_path);\n",
    "key = 'slc_{}_1x1 Columns'.format(str(segments[0]))\n",
    "samples = int(slc_info_dict[key]);\n",
    "lines = 0;\n",
    "for seg in segments:\n",
    "    key = 'slc_{}_1x1 Rows'.format(str(seg))\n",
    "    lines += int(slc_info_dict[key]);\n",
    "print('total samples/columns:',samples);\n",
    "print('total rows:',lines) \n",
    "lats= [];lons= [];\n",
    "try:\n",
    "    bbox\n",
    "except:\n",
    "    for seg in segments:\n",
    "        for corner in [1,2,3,4]:\n",
    "            lat, lon = slc_info_dict['Segment {} Data Approximate Corner 1'.format(seg,corner)].split(',')\n",
    "            lats.append(float(lat));lons.append(float(lon));\n",
    "    bbox = ' '.join(map(str,[int(np.min(lats)-0.1),int(np.max(lats)+0.1),int(np.min(lons)-0.1),int(np.max(lons)+0.1)]));\n",
    "print('Bounding box for DEM:',bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132e2c3",
   "metadata": {},
   "source": [
    "### Download SRTM DEM \n",
    "\n",
    "- If using own DEM is preferred, point to it as dem_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548cabe-c407-42e7-8399-f9dab6ebb93d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get DEM for geocoding\n",
    "#if you have your DEM file deifne its path as dem_file '/path/to/dem_file' if not SRTM DEM will be used\n",
    "#define bounding box for the DEM\n",
    "try:\n",
    "    dem_file\n",
    "except:\n",
    "    dem_dir = os.path.join(out_dir,'DEM');\n",
    "    os.makedirs(dem_dir, exist_ok=True);\n",
    "    os.chdir(dem_dir);\n",
    "    source_link =\"http://step.esa.int/auxdata/dem/SRTMGL1/\"\n",
    "    try:\n",
    "        bbox\n",
    "    except:\n",
    "        print('Bounding box for DEM download required');\n",
    "    cmd ='dem.py -a stitch -b {} -u {} -d {} -r -s 1 -c'.format(bbox,source_link,dem_dir);\n",
    "    print(cmd);\n",
    "    run_cmd(cmd);\n",
    "    \n",
    "dem_file = glob.glob(os.path.join(dem_dir, \"*.dem.wgs84\"))[0];\n",
    "cmd = 'fixImageXml.py -f -i {}'.format(dem_file)\n",
    "print(cmd);\n",
    "os.system(cmd);\n",
    "os.chdir(out_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe153f9",
   "metadata": {},
   "source": [
    "### Create interferogram pairs list\n",
    "- Based on the numConnections variable input earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6de1-874d-4c6e-ba36-f50016d6d6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create pairs\n",
    "looks = [alks, rlks];\n",
    "ifg_dir =  os.path.join(out_dir,'Igrams');\n",
    "os.makedirs(ifg_dir, exist_ok=True);\n",
    "pairs_list= [];\n",
    "for ii,dd in enumerate(dateList):\n",
    "    referenceDate = dd;\n",
    "    for jj in range(ii+1, ii+1+numConnections):\n",
    "        if jj < len(dateList):\n",
    "            secondaryDate = dateList[jj];\n",
    "            ifg_pair =  referenceDate+'_'+secondaryDate;\n",
    "            pairs_list.append(ifg_pair);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b595268",
   "metadata": {},
   "source": [
    "## Generate Interferometic products\n",
    "- The code multilooks the SLCs and creates interferograms. Processes multiple segments simultenously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e4c14-acb4-48ba-ac04-55c8c56aa860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate interferograms\n",
    "def generate_isce_xml(ifg_file, amp_file, coh_file, samples):\n",
    "    outInt = isceobj.Image.createIntImage()\n",
    "    outInt.setFilename(ifg_file)\n",
    "    outInt.setWidth(samples)\n",
    "    outInt.setAccessMode('read')\n",
    "    outInt.renderHdr()\n",
    "    outInt.renderVRT()\n",
    "\n",
    "    outAmp = isceobj.Image.createAmpImage()\n",
    "    outAmp.setFilename(amp_file)\n",
    "    outAmp.setWidth(samples)\n",
    "    outAmp.setAccessMode('read')\n",
    "    outAmp.renderHdr()\n",
    "    outAmp.renderVRT()\n",
    "\n",
    "    outCor = isceobj.Image.createImage()\n",
    "    outCor.setFilename(coh_file)\n",
    "    outCor.setWidth(samples)\n",
    "    outCor.setAccessMode('read')\n",
    "    outCor.setDataType('FLOAT')\n",
    "    outCor.renderHdr()\n",
    "    outCor.renderVRT()\n",
    "\n",
    "def cat_and_interfere(slc_dir,samples,looks,segments,ifg_dir,pair):\n",
    "    referenceDate,secondaryDate = pair.split('_');\n",
    "    int_dir  = os.path.join(ifg_dir,referenceDate+'_'+secondaryDate);os.makedirs(int_dir, exist_ok=True);\n",
    "    intf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.int');\n",
    "    ampf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.amp');\n",
    "    cohf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.coh');\n",
    "    igram = Interferogram(samples, looks);\n",
    "    int_samples = samples//looks[1];\n",
    "\n",
    "    if len(segments)>1:\n",
    "        with open(intf, 'wb') as fint, open(ampf, 'wb') as famp:\n",
    "            for seg in segments:\n",
    "                ref_img = slc_dir[:-1]+str(seg)+'/'+referenceDate+'/'+referenceDate+'.slc';#print(ref_img)\n",
    "                sec_img = slc_dir[:-1]+str(seg)+'/'+secondaryDate+'/'+secondaryDate+'.slc';#print(sec_img)\n",
    "                img0 = ImageReader(ref_img, samples, dtype='complex64')\n",
    "                img1 = ImageReader(sec_img, samples, dtype='complex64')\n",
    "                #log.info('... %s * conj(%s)', img0.filename, img1.filename)\n",
    "                for int_row, amp_row in igram.iterrows(img0, img1):\n",
    "                    int_row.tofile(fint);\n",
    "                    amp_row.tofile(famp);\n",
    "        correlation(intf, ampf, cohf);\n",
    "        generate_isce_xml(intf, ampf, cohf, int_samples)\n",
    "    else:\n",
    "        ref_img = slc_dir+'/'+referenceDate+'/'+referenceDate+'.slc';#print(ref_img)\n",
    "        sec_img = slc_dir+'/'+secondaryDate+'/'+secondaryDate+'.slc';#print(sec_img)\n",
    "        with open(intf, 'wb') as fint, open(ampf, 'wb') as famp:\n",
    "            img0 = ImageReader(ref_img, n, dtype='complex64')\n",
    "            img1 = ImageReader(sec_img, n, dtype='complex64')\n",
    "            #log.info('... %s * conj(%s)', img0.filename, img1.filename)\n",
    "            for int_row, amp_row in igram.iterrows(img0, img1):\n",
    "                    int_row.tofile(fint);\n",
    "                    amp_row.tofile(famp);\n",
    "        correlation(intf, ampf, cohf);\n",
    "        generate_isce_xml(intf, ampf, cohf, int_samples)\n",
    "with multiprocessing.Pool(processes=12) as pool:\n",
    "    pool.starmap(cat_and_interfere,[(slc_dir,samples,looks,segments,ifg_dir,pair) for pair in pairs_list]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b2339",
   "metadata": {},
   "source": [
    "## Unwrap the interferograms using SNAPHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1819ca-ec79-4b0e-8ecd-c8051c602eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unwrap interferograms\n",
    "\n",
    "def unwrap_snaphu(unwrap_method,defo_max,looks,slc_dir,ifg_dir,pair):\n",
    "    referenceDate,secondaryDate = pair.split('_');\n",
    "    reference_slc_dir = slc_dir+'/'+referenceDate\n",
    "    int_dir  = os.path.join(ifg_dir,referenceDate+'_'+secondaryDate);\n",
    "    intf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.int');\n",
    "    unwf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.unw');\n",
    "    cohf =  os.path.join(int_dir,referenceDate+'_'+secondaryDate+'.coh');\n",
    "    cmd = ['unwrap.py -i {} -c {} -u {} -s {}/ -a {} -r {} -d {} -m {}'.format(intf,cohf,unwf,reference_slc_dir,looks[0],looks[1],defo_max,unwrap_method)];\n",
    "    run_cmd(cmd)\n",
    "unwrap_method = 'snaphu';\n",
    "defo_max = 2;\n",
    "for pair in pairs_list:\n",
    "    unwrap_snaphu(unwrap_method, defo_max, looks, slc_dir, ifg_dir, pair);\n",
    "    \n",
    "#####Currently not working, crashing the instance ########\n",
    "# with multiprocessing.Pool(processes=12) as pool:\n",
    "#     pool.starmap(unwrap_snaphu,[(unwrap_method,defo_max,looks,slc_dir,ifg_dir,pair) for pair in pairs_list]);\n",
    "# if __name__ == \"__main__\":\n",
    "#     with ProcessPoolExecutor(max_workers=12) as executor:\n",
    "#         executor.map(unwrap_snaphu, pairs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031b8d9",
   "metadata": {},
   "source": [
    "### Generate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dcf225-3113-4640-8429-baa0b21e20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create UAVSAR baselines\n",
    "baselines_dir = os.path.join(out_dir,'baselines');\n",
    "os.makedirs(baselines_dir, exist_ok=True);\n",
    "cmd ='uavsar_baselines.py -s {} -b {}  -m {}'.format(slc_dir,baselines_dir,reference_slc_dir);\n",
    "print(cmd);\n",
    "run_cmd(cmd);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb2441",
   "metadata": {},
   "source": [
    "### Generate geometry files from the DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f9e7d-6adf-4623-ae85-65f8b0a0fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate geometry files\n",
    "geometery_dir = os.path.join(out_dir,'geometry'+str(alks)+'x'+str(rlks));\n",
    "cmd = 'topo.py -a {} -r {} -d {} -m {} -o {} -n'.format(alks, rlks,dem_file,reference_slc_dir,geometery_dir);\n",
    "print(cmd);\n",
    "run_cmd(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a073b4",
   "metadata": {},
   "source": [
    "### Copy referenceShelve directory from the master interferogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68326b-2f2f-4366-a1ae-ba7ba5748b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create referenceShelve dir\n",
    "reference_dir = os.path.join(out_dir,'referenceShelve');\n",
    "reference_ifg = sorted(glob.glob(ifg_dir+'/'+reference_date+'_*'))[0];\n",
    "print('Reference interferogram is:',reference_ifg)\n",
    "cmd ='cp -r {}/referenceShelve {}'.format(reference_ifg,reference_dir)\n",
    "print(cmd);\n",
    "run_cmd(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815ef6c",
   "metadata": {},
   "source": [
    "## Prepare interferograms and geometry files to be loaded into MintPy.\n",
    "- This step requires an environment with both ISCE and MintPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2215a6b-8761-41e3-aff4-764319d66196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare .rsc files for unwrapped interferograms to be loaded into MintPy\n",
    "cmd = 'prep_isce.py -f {}/*/{} -m {}/data -b {}  -g {}'.format(ifg_dir,'*.unw',reference_dir,baselines_dir,geometery_dir)\n",
    "print(cmd);\n",
    "run_cmd(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff898e0c",
   "metadata": {},
   "source": [
    "### Add paths pointing the inteferometric and geometry files to the smallbaselineApp.cfg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae6b6f-68f3-4da4-a51e-0de907a81150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mintpy_dir= os.path.join(out_dir,'mintpy');\n",
    "os.makedirs(mintpy_dir, exist_ok=True);\n",
    "config_file = Path(mintpy_dir)/('smallbaselineApp.cfg')\n",
    "config_file_parameters = \"\"\"\n",
    "####mintpy parameters\n",
    "mintpy.load.processor = isce\n",
    "mintpy.compute.numWorker = auto\n",
    "##path to interferograms\n",
    "mintpy.load.autoPath = no\n",
    "mintpy.load.metaFile       = {out_dir}/referenceShelve/data\n",
    "mintpy.load.baselineDir    = {out_dir}/baselines  \n",
    "mintpy.load.unwFile        = {out_dir}/Igrams/*/*.unw_snaphu.unw  \n",
    "mintpy.load.corFile        = {out_dir}/Igrams/*/*.coh\n",
    "mintpy.load.connCompFile   = {out_dir}/Igrams/*/*.unw_snaphu.conncomp  \n",
    "#mintpy.load.intFile        = {out_dir}/Igrams/*/*.int  \n",
    "###path to geometry files\n",
    "mintpy.load.demFile = {out_dir}/{geometery_dir}/hgt.rdr\n",
    "mintpy.load.lookupYFile = {out_dir}/{geometery_dir}/lat.rdr\n",
    "mintpy.load.lookupXFile = {out_dir}/{geometery_dir}/lon.rdr\n",
    "mintpy.load.incAngleFile = {out_dir}/{geometery_dir}/los.rdr\n",
    "mintpy.load.azAngleFile = {out_dir}/{geometery_dir}/los.rdr\n",
    "mintpy.load.shadowMaskFile = {out_dir}/{geometery_dir}/shadowMask.msk\n",
    "\"\"\".format(out_dir=out_dir,geometery_dir=geometery_dir)\n",
    "config_file.write_text(config_file_parameters);\n",
    "print('MintPy config file:\\n    {}:'.format(config_file))\n",
    "print(config_file.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c3971",
   "metadata": {},
   "source": [
    "## Load files to make MintPy input data cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9b2ab-f65e-4dd9-b6e4-584c72e1552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(mintpy_dir);\n",
    "cmd = 'smallbaselineApp.py ' + 'smallbaselineApp.cfg' + ' --dostep load_data'\n",
    "print(cmd);\n",
    "run_cmd(cmd);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isce",
   "language": "python",
   "name": "isce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
