#!/usr/bin/env python
usage = """
unwrap.py [options] dir

Unwrap all interferograms in a given directory.  Optionally apply the integer
phase ambiguity to higher resolution data in another directory.

In addition to the interferograms (.int files), the directory must also contain
the correlation (.cor files) and int.json file (typically produced by the
script cat_and_interfere.py).  The unwrapped phase will be written to .unw
files.

Options:
    --cor-reject <x>
        Correlation below which data will be ignored (0<x<1.0, default=0.4).

    --cor-source <x>
        Minimum correlation to consider a pixel good enough to use as a basis
        for inpainting bad data (0<x<1, default=0.45).

    --radius <r>
        Radius of smoothing filter (really the stdev of a gaussian, default=3).

    --highres <dir>
        After unwrapping data, the same integer phase cycle ambiguity
        will be upscaled and applied to the higher resolution data in this
        directory.

    --clean
        Don't save temporary files.
"""

from datetime import datetime
from getopt import getopt, GetoptError
from glob import glob
import h5py
from insar import ImageReader
import json
import logging
import numpy as np
import os
from scipy.ndimage import distance_transform_edt
from scipy.ndimage import gaussian_filter
import subprocess as sub
from string import Template
import sys
import isce
import isceobj

log = logging.getLogger('unwrap')


DEFAULT_COR_REJECT = 0.4 # 0.4 , .0001
DEFAULT_COR_SOURCE = 0.45  # 0.45 , 0.05
DEFAULT_RADIUS = 3.0


def unwrap_pre(intf_name, cor_name, n, out_int, out_info,
               cor_reject=DEFAULT_COR_REJECT, cor_source=DEFAULT_COR_SOURCE,
               sigma=DEFAULT_RADIUS):
    """Given interferogram and correlation data files, replace low correlation
    pixels with reasonable smooth data to aid unwrapping.

    Inputs:
        intf_name   File name of complex64 interferogram data.
        cor_name    File name of float32 correlation data.
        n           Number of range samples in both files.
        out_int     File name to save easy-to-unwrap interferogram.
        out_info    File name to store data necessary for reconstruction.

    Options:
        cor_reject  Lowest acceptable correlation value.
        cor_source  Minimum correlation of replacement values.
        sigma       Standard deviation of gaussian smoothing filter, in pixels.
    """
    log.debug('Loading interferogram %s', intf_name)
    intf = np.fromfile(intf_name, dtype='c8')
    log.debug('Loading correlation %s', cor_name)
    cor = np.fromfile(cor_name, dtype='f4')
    intf.shape = cor.shape = -1, n
    
    # The name of the mask file
    mask_low = intf_name[:-4] + '.mask'
    
    # The name of the water mask file
    mask_water_low =  intf_name[:-4] + '.wmask'

    # Load the mask in case it exists
    if os.path.exists(mask_low):
         log.debug('Loading mask %s', mask_low)
         mask = np.fromfile(mask_low, dtype='f4')
         mask.shape = -1, n

    # Load the mask in case it exists
    if os.path.exists(mask_water_low):
         log.debug('Loading mask %s', mask_water_low)
         wmask = np.fromfile(mask_water_low, dtype='f4')
         wmask.shape = -1, n
     
    # Figure out which pixels are bad.
    log.debug('Discarding pixels with correlation < %f.', cor_reject)
    bad = cor < cor_reject

    # adding the mask in
    if 'mask' in locals():
        bad = bad + mask<1
    # adding the mask in
    if 'wmask' in locals():
        print("good")



    bad_phase = np.angle(intf[bad])
    # Find the indices of nearest source data for each pixel.
    log.debug('Finding nearby pixels with correlation >= %f.', cor_source)
    d, nearest = distance_transform_edt(cor < cor_source, return_indices=True)
    # Replace bad data with nearest source data.
    log.debug('Replacing data')
    nearest = nearest[0][bad], nearest[1][bad]
    intf[bad] = intf[nearest]
    # Smooth the replacement data.  Use 0 for data out-of-bounds.
    log.debug('Smoothing data (sigma=%f).', sigma)
    smooth_x = gaussian_filter(intf.real, sigma, mode='constant', cval=0.0)
    smooth_y = gaussian_filter(intf.imag, sigma, mode='constant', cval=0.0)
    intf[bad] = smooth_x[bad] + 1j*smooth_y[bad]
    
    log.debug('Saving faux interferogram to file %s.', out_int)
    intf.tofile(out_int)
    log.debug('Saving reconstruction info file %s.', out_info)
    h5 = h5py.File(out_info, 'w')
    h5.attrs['n'] = n
    h5.create_dataset('mask', data=bad, compression='gzip')
    h5.create_dataset('nearest', data=nearest, compression='gzip')
    h5.create_dataset('phase', data=bad_phase, compression='gzip')
    h5.close()


# Template for SNAPHU program.  Variable names match JSON data generated by
# cat_and_interfere.py
snaphu_conf = Template("""
# snaphu configuration file

# File formats
INFILEFORMAT		COMPLEX_DATA
OUTFILEFORMAT		FLOAT_DATA
CORRFILEFORMAT		FLOAT_DATA

# Deformation mode
STATCOSTMODE DEFO

# Tile control
# TILECOSTTHRESH 	500 # Added by TO

# Connected components (use -g to produce connection mask)
CONNCOMPFILE 		.conncomp
CONNCOMPTHRESH		500 # 200 or 300
MINCONNCOMPFRAC		0.00005 # 0.0005
MAXNCOMPS               256 # 150 before 32

# Input file line length
LINELENGTH    ${samples_int}

# Number of looks
NLOOKSRANGE	${looks_range}
NLOOKSAZ	${looks_azimuth}

NCORRLOOKS	194  # = 36/0.6 -- CJ note sb 36*0.6

# Maximum phase discontinuity likely (double).  Units are radians or cycles.
# If abrupt phase discontinuities are not expected, this paramter can be
# set to zero.
DEFOMAX_CYCLE	1.5 # 1.2 / 1.5
DEFOCONST       0.7 # 0.5
RHOSCONST2      0.35 # 0.24

# Algorithm used for initialization of wrapped phase values.  Possible
# values are MST and MCF.
INITMETHOD    MCF
""")

def unwrap(intf_name, unw_name, cor_name=None, conf_name=None):
    """Unwrap an interferogram using SNAPHU.

    intf_name   Input interferogram file name.  Flat complex64 binary file.
    unw_name    Output unwrapped phase file (float32).
    cor_name    Input correlation file, or None.
    conf_name   Input SNAPHU config file, or None to generate from int.json.

    NOTE: The default configuration assumes smooth input phase data.

    If no SNAPHU configuration is given, image dimensions will be read from
    the int.json file in the same directory as intf_name.  This file is
    typically produced by the script cat_and_interefere.py.
    """
    log.debug('Generating unwrapped phase file %s.', unw_name)
    # If we're not given a SNAPHU config file generate one.
    if conf_name is None:
        conf_name = unw_name + '.conf'
        log.debug('Looking for metadata in int.json file.')
        js_name = os.path.join(os.path.dirname(intf_name), 'int.json')
        if not os.path.exists(js_name):
            raise IOError('No SNAPHU config file and no int.json file.')
        with open(js_name) as f:
            js = json.load(f)
        log.debug('Writing SNAPHU config %s.', conf_name)
        with open(conf_name, 'w') as f:
            f.write(snaphu_conf.substitute(js))
    else:
        log.debug('Using supplied SNAPHU config %s.', conf_name)
        assert os.path.exists(conf_name)

    conncomp_name = unw_name + '.conncomp'

    args = ['snaphu', '-v', intf_name,'-f', conf_name, '-g', conncomp_name, '-o', unw_name ]
    if cor_name:
        args += ['-c', cor_name]
    log.debug('Calling SNAPHU: %s', ' '.join(args))
    sub.check_call(args)


def unwrap_post(unw_name, h5_name, out_name):
    """Given an unwrapped file and the metadata from unwrap_pre, restore the low
    correlation phase data using an appropriate integer wrap.
    """
    log.debug('Loading HDF5 unwrapping metadata %s', h5_name)
    h5 = h5py.File(h5_name, 'r')
    n = h5.attrs['n']
    log.debug('Reading unwrapped phase %s', unw_name)
    unw = np.fromfile(unw_name, dtype='f4')
    unw.shape = -1, n

    log.debug('Restoring original phase values.')
    mask = np.asarray(h5['mask'])
    orig = np.asarray(h5['phase'])
    i, j = np.asarray(h5['nearest'])
    near = unw[i,j]
    pi = np.pi
    unw[mask] = np.mod(orig - near + pi, 2*pi) + near - pi

    log.debug('Writing to file %s.', out_name)
    unw.tofile(out_name)


def apply_phasemask(unw, intf, out):
    """Apply the integer phase ambiguity in the unwrapped phase file unw to the
    phase in complex file intf, writing the result to out.  You should use this
    routine to apply an unwrapping solution obtained on low resolution data
    back to a higher resolution version of the same data.

    It's assumed that unw and intf are both described by an int.json file in the
    same directory of each.  This file is typically produced by the script
    cat_and_interefere.py.
    """
    log.debug('Applying phase from %s to %s.', unw, intf)
    # Load JSON data.  Maybe take these as parameters instead?
    unw_json = os.path.join(os.path.dirname(unw), 'int.json')
    int_json = os.path.join(os.path.dirname(intf), 'int.json')
    log.debug('Looking for metadata in %s.', unw_json)
    if not os.path.exists(unw_json):
        raise IOError('Could not find int.json file for unwrapped data.')
    log.debug('Looking for metadata in %s.', int_json)
    if not os.path.exists(int_json):
        raise IOError('Could not find int.json file for complex data.')
    with open(unw_json) as fp:
        unw_info = json.load(fp)
    with open(int_json) as fp:
        int_info = json.load(fp)

    # Make sure we've got compatible data file dimensions.
    if any([unw_info['looks_range'] < int_info['looks_range'],
            unw_info['looks_azimuth'] < int_info['looks_azimuth']]):
        raise ValueError('Expected lower resolution unwrapped phase.')
    if any([unw_info['looks_range'] % int_info['looks_range'],
            unw_info['looks_azimuth'] % int_info['looks_azimuth']]):
        raise ValueError('Expected an integral number of looks intf->unw.')

    # Figure out number of output lines per input line.
    ratio_rg = unw_info['looks_range'] // int_info['looks_range']
    ratio_az = unw_info['looks_azimuth'] // int_info['looks_azimuth']
    log.debug('Dimension ratios (rg,az) = (%d,%d).', ratio_rg, ratio_az)

    # Compute mapping of one row of input to one block of output.
    nin = unw_info['samples_int']
    nout = int_info['samples_int']
    #assert nout == ratio_rg * nin

    n = ratio_rg * nin
    # Repeat columns, e.g. [0,1,2] -> [0,0,1,1,2,2]                                                                                                                     
    j = np.column_stack(ratio_rg * (np.arange(nin),)).reshape(n)
    # Careful, nout might not be a multiple of ratio_rg.  In that case just                                                                                             
    # repeat the last valid input column, e.g.                                                                                                                          
    # [0,0,1,1,2,2] -> [0,0,1,1,2,2,2]                                                                                                                                  
    if n < nout:
        log.debug("Output samples don't divide evenly.  Repeating a column.")
        repeat = nout - n
        j = np.hstack((j, repeat * (j[-1],)))
    assert len(j) == nout


    idx = np.row_stack(ratio_az * (j,))

  # Now do the thang.
    log.debug('Writing unwrapped phase to %s.', out)
    unw_reader = ImageReader(unw, nin, 'float32')
    int_reader = iter(ImageReader(intf, nout, 'complex64'))
    buf = np.zeros((ratio_az, nout), dtype='float32')
    twopi = 2 * np.pi
    with open(out, 'wb') as fp:
        for unw_row in unw_reader:
            # Expand low-resolution unwrapped data to output posting.
            lowres = unw_row[idx]
            # Read in the corresponding block of wrapped data.
            for i in range(ratio_az):
                buf[i,:] = np.angle(next(int_reader))
            # Do some fancy modular arithmetic to apply the phase ambiguity.
            dx = buf - lowres
            ambig = twopi * np.around(dx / twopi)
            hires = buf - ambig
            # Be sure to write single-precision data.
            assert hires.dtype == np.dtype('float32')
            hires.tofile(fp)
        # What to do with extra high-res lines w/o low-res support?
        # Conservatively could output zeros.
        # Ambitiously could actually unwrap based on gradients.
        # Middle ground is to re-use the last ambiguity, which can be wrong, but
        # may be preferable to zeros (or truncated files).
        for i, int_row in enumerate(int_reader):
            assert i < ratio_az, 'Too many leftover lines.'
            hires = np.angle(int_row) - ambig[-1,:]
            hires.tofile(fp)
    conncomp_file = unw[:-4]+'.int.pre.unw.conncomp'
    conncomp_reader = ImageReader(conncomp_file, nin, 'int8');
    in_lines = os.path.getsize(intf) // (nout*np.dtype('complex64').itemsize);
    lost_lines = in_lines - np.shape(conncomp_reader)[0]*ratio_az;

    conncomp_file_out = intf[:-4]+'.unw.conncomp'
    with open(conncomp_file_out, 'wb') as fp:
        for comp_row in conncomp_reader:
            hires_comp = comp_row[idx];
            hires_comp.tofile(fp);
        if lost_lines > 0:
            for line in range(lost_lines):
                hires_comp[-1,:].tofile(fp)
                
def isce_xml_unw(unwrapFile, width,length,n_bands):
    outImage = isceobj.Image.createUnwImage()
    outImage.setFilename(unwrapFile)
    outImage.setWidth(width)
    outImage.setLength(length)
    outImage.bands = int(n_bands);
    #outImage.dataType = 'FLOAT'
    outImage.setAccessMode('read')
    outImage.renderHdr()
    outImage.renderVRT()
    ## generate xml file for conncomp
    conncomp_file = unwrapFile+'.conncomp'
    conncomp_xml_file = conncomp_file+'.xml';
    if os.path.exists(conncomp_file) and not os.path.exists(conncomp_xml_file):
        connImage = isceobj.Image.createImage()
        connImage.setFilename(conncomp_file)
        #At least one can query for the name used
        connImage.setWidth(width)
        connImage.setLength(length)
        connImage.setAccessMode('read')
        connImage.setDataType('BYTE')
        connImage.renderHdr()
        connImage.renderVRT()


def main(argv):
    # Parse command line arguments.
    try:
        options = "r:h"
        long_options = ['help', 'cor-reject=', 'cor-source=', 'radius=',
                        'highres=', 'clean']
        opts, args = getopt(argv[1:], options, long_options)
    except GetoptError as e:
        print (e)
        print (usage)
        sys.exit(1)

    # Set up defaults.
    dir_hi = None
    cor_reject = DEFAULT_COR_REJECT
    cor_source = DEFAULT_COR_SOURCE
    clean = False
    radius = DEFAULT_RADIUS

    # Process options.
    for o, a in opts:
        if o in ('-h', '--help'):
            print (usage)
            sys.exit(1)
        elif o in ('-r', '--radius'):
            radius = float(a)
        elif o == '--cor-reject':
            cor_reject = float(a)
        elif o == '--cor-source':
            cor_source = float(a)
        elif o == '--highres':
            dir_hi = a
        elif o == '--clean':
            clean = True
        else:
            assert False, 'Unhandled option.'

    if len(args) < 1:
        print (usage)
        sys.exit(1)

    dir_low = args[0]
    if dir_hi is None:
        dir_hi = dir_low

    for intf in glob(os.path.join(dir_hi, '*/*.int')):
        # Avoid work if possible.
        # If --highres=dir_hi option is given, assume that the high-resolution
        # products are the ones of interest (e.g., still skip if low-res unw
        # does not exist).
        unw = intf[:-4] + '.unw'
        if os.path.exists(unw):
            log.debug('Skipping %s because it already exists.', unw)
            continue
        # Make sure necessary input files exist.
        intf_low_dir =os.path.basename(os.path.split(intf)[0]);
        intf_low = os.path.join(dir_low, intf_low_dir, os.path.split(intf)[1])
        cor_low = intf_low[:-4] + '.coh' # TO modif
        if os.path.isfile(cor_low) == False:
            cor_low = intf_low[:-4] + '.cor'
        info_low = os.path.join(dir_low, 'int.json')
        for f in (intf_low, cor_low, info_low):
            if not os.path.exists(f):
                raise IOError('Could not find %s needed to make %s.' % (f, unw))
        # checking of the low res product already exists, if yes skip it as it could be phase corrected
        unw_low = intf_low.replace('.int', '.unw')      # DB: start 29 June 2016
        if os.path.exists(unw_low):
            log.debug('Skipping %s because it already exists.', unw_low)
            pre_int = intf_low + '.pre'
            pre_info = intf_low + '.pre.h5'
        else:
            # Inpaint low correlation areas of the interferogram.
            with open(info_low) as f:
                n = json.load(f)['samples_int']
            pre_int = intf_low + '.pre'
            pre_info = intf_low + '.pre.h5'
            unwrap_pre(intf_low, cor_low, n, pre_int, pre_info,
                   cor_reject=cor_reject, cor_source=cor_source, sigma=radius)
            # Unwrap the simplified interferogram with SNAPHU.
            pre_unw = pre_int + '.unw'
#            unwrap(pre_int, pre_unw)   # original version of the code 
            unwrap(pre_int, pre_unw, cor_low)   # Use this command if you want snaphu to account for real coherence
            # Put the original data back in on a reasonable phase ambiguity.
            unw_low = intf_low.replace('.int', '.unw')
            unwrap_post(pre_unw, pre_info, unw_low)     # DB: end 
        
        # Apply the low resolution phase ambiguity solution to high res data.
        if unw != unw_low:
            apply_phasemask(unw_low, intf, unw)
        if clean:
            log.debug('Removing temporary files.')
            for f in (pre_int, pre_info):
                if os.path.exists(f):        #DB: start 29 June 2016
                    os.remove(f)             #DB: end

        log.debug(' ')     # DB: start,end 29 June 2016 

if __name__ == '__main__':
    log_level = logging.DEBUG
    log.setLevel(log_level)
    sh = logging.StreamHandler()
    sh.setLevel(log_level)
    log.addHandler(sh)

    main(sys.argv)
