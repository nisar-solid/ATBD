{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8d77a2-b3ea-47a1-9f9f-f49d0ed160ab",
   "metadata": {},
   "source": [
    "# Preparing ARIA Sentinel-1 data for validation of Solid Earth requirements\n",
    "\n",
    "**Original code authored by:** David Bekaert, Heresh Fattahi, Eric Fielding, and Zhang Yunjun  <br>\n",
    "Extensive modifications by Adrian Borsa and Amy Whetter 2022 <br>\n",
    "Reorganized and modified by Ekaterina Tymofyeyeva, March 2024 <br>\n",
    "Clean up and new functionality by Emre Havazli, April 2025\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This notebook pre-processes data for different NISAR Solid Earth calval sites amd requirements. Subsequent validation is done via separate notebooks for the Transient, Secular, and Coseismic requirements. These are located under /ATBD_main/methods/.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397daf73-728b-4e62-a25e-2d321f41384f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr/>\n",
    "\n",
    "## Table of Contents: <a id='prep_TOC'></a>\n",
    "\n",
    "[**Environment Setup**](#setup)\n",
    "- [Load Python Packages](#load_packages)\n",
    "- [Define CalVal Site and Parameters](#set_calval_params)\n",
    "- [Define Directories](#set_directories)\n",
    "- [Authentication](#set_authentication)\n",
    "\n",
    "[**1. Download and Prepare Interferograms**](#prep_ifg)\n",
    "- [1.1.  Download Interferograms](#prep_download_ifg)\n",
    "- [1.2.  Crop Interferograms](#prep_crop_ifg)\n",
    "- [1.3.  Set Up MintPy Configuration file](#prep_setup_config)\n",
    "- [1.4.  Load Data into MintPy](#prep_load_data)\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b4566-7905-4d0e-8e4a-097266495e61",
   "metadata": {},
   "source": [
    "<a id='#setup'></a>\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831854a8-9258-46fd-a136-ffa7ef9f72d8",
   "metadata": {},
   "source": [
    "### Load Python Packages <a id='#load_packages'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae784898-3e41-4463-a3f9-bd701a80dd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import netrc\n",
    "import os\n",
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a433c2-ce25-40bc-a1db-f5c4506d3e01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Calval Site and Parameters <a id='set_calval_params'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b464e26-d7a9-4834-bc77-da3968e90f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic Configuration ===\n",
    "site = \"CalVal_S1_LosAngelesA64\"  # Cal/Val location ID\n",
    "requirement = \"Secular\"  # Options: 'Secular', 'Coseismic', 'Transient'\n",
    "dataset = \"ARIA_S1_new\"  # Dataset type: 'ARIA_S1', 'ARIA_S1_new'\n",
    "aria_gunw_version = \"3_0_1\"\n",
    "\n",
    "rundate = \"20250818\"  # Date of this Cal/Val run\n",
    "version = \"1\"         # Version of this Cal/Val run\n",
    "custom_sites = \"/home/jovyan/my_sites.txt\"  # Path to custom site metadata\n",
    "\n",
    "# === Username Detection / Creation ===\n",
    "user_file = \"/home/jovyan/me.txt\"\n",
    "if os.path.exists(user_file):\n",
    "    with open(user_file, \"r\") as f:\n",
    "        you = f.readline().strip()\n",
    "else:\n",
    "    you = input(\"Please type a username for your Cal/Val outputs: \").strip()\n",
    "    with open(user_file, \"w\") as f:\n",
    "        f.write(you)\n",
    "\n",
    "# === Load Cal/Val Site Metadata ===\n",
    "try:\n",
    "    with open(custom_sites, \"r\") as f:\n",
    "        sitedata = json.load(f)\n",
    "    site_info = sitedata[\"sites\"][site]\n",
    "except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "    raise RuntimeError(f\"Failed to load site metadata from {custom_sites}: {e}\")\n",
    "except KeyError:\n",
    "    raise ValueError(f\"Site ID '{site}' not found in {custom_sites}\")\n",
    "\n",
    "print(f\"Loaded site: {site}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00c720-2ba2-4843-a667-f2411f468204",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Directories and Files <a id='set_directories'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3be183-ef89-4ad9-b4e8-498bd85d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static base directory for Cal/Val processing\n",
    "BASE_DIR = \"/scratch/nisar-st-calval-solidearth\"\n",
    "\n",
    "# Define key path components\n",
    "site_dir = os.path.join(BASE_DIR, dataset, site)\n",
    "work_dir = os.path.join(site_dir, requirement, you, rundate, f\"v{version}\")\n",
    "gunw_dir = os.path.join(site_dir, \"products\")\n",
    "mintpy_dir = os.path.join(work_dir, \"MintPy\")\n",
    "\n",
    "# Create required directories\n",
    "for path in [work_dir, gunw_dir, mintpy_dir]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Log directory structure\n",
    "print(f\"  Work directory: {work_dir}\")\n",
    "print(f\"  GUNW directory: {gunw_dir}\")\n",
    "print(f\"MintPy directory: {mintpy_dir}\")\n",
    "\n",
    "# Configuration file path\n",
    "site_code = site_info.get('calval_location')\n",
    "config_file = os.path.join(mintpy_dir, f\"{site_code}.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a50541-6604-400f-ac7e-c14361dc8dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Authentication <a id='set_authentication'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1328ea4-a4a3-452d-905e-0e4f3c5d795c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_permission(path, mode=0o600):\n",
    "    if os.path.exists(path):\n",
    "        os.chmod(path, mode)\n",
    "\n",
    "# === Earthdata Login ===\n",
    "fnetrc = os.path.expanduser(\"~/.netrc\")\n",
    "earthdata_host = \"urs.earthdata.nasa.gov\"\n",
    "earthdata = False\n",
    "\n",
    "if os.path.exists(fnetrc):\n",
    "    ensure_permission(fnetrc)\n",
    "    nrc = netrc.netrc()\n",
    "    credentials = nrc.authenticators(earthdata_host)\n",
    "    if credentials:\n",
    "        earthdata_user, _, earthdata_password = credentials\n",
    "        earthdata = True\n",
    "        print(f\"Earthdata credentials found for user: {earthdata_user}\")\n",
    "\n",
    "if not earthdata:\n",
    "    print(\"\\nNEEDED to Download ARIA GUNWs\")\n",
    "    print(\"Create account at: https://urs.earthdata.nasa.gov/\")\n",
    "    earthdata_user = input(\"Earthdata username: \").strip()\n",
    "    earthdata_password = input(\"Earthdata password: \").strip()\n",
    "    with open(fnetrc, \"a\") as f:\n",
    "        f.write(f\"machine {earthdata_host}\\nlogin {earthdata_user}\\npassword {earthdata_password}\\n\")\n",
    "    ensure_permission(fnetrc)\n",
    "    print(\"Earthdata credentials saved.\")\n",
    "\n",
    "\n",
    "# === OpenTopography API Key ===\n",
    "fopentopo = os.path.expanduser(\"~/.topoapi\")\n",
    "if os.path.exists(fopentopo):\n",
    "    ensure_permission(fopentopo)\n",
    "    with open(fopentopo) as f:\n",
    "        opentopography_api_key = f.read().strip()\n",
    "else:\n",
    "    print(\"\\nNEEDED To Download DEMs:\")\n",
    "    print(\"Register at: https://portal.opentopography.org/login\")\n",
    "    print(\"Navigate: My Account → myOpenTopo Authorizations and API Key → Request API key\")\n",
    "    opentopography_api_key = input(\"OpenTopo API key: \").strip()\n",
    "    with open(fopentopo, \"w\") as f:\n",
    "        f.write(opentopography_api_key + \"\\n\")\n",
    "    ensure_permission(fopentopo)\n",
    "    print(\"OpenTopography API key saved.\")\n",
    "\n",
    "# === CDS (ERA5) API Key ===\n",
    "cds_config_path = os.path.expanduser(\"~/.cdsapirc\")\n",
    "if not os.path.exists(cds_config_path):\n",
    "    print(\"\\nNEEDED to use ERA5 correction:\")\n",
    "    print(\"Register and get token: https://cds.climate.copernicus.eu/how-to-api\")\n",
    "    cds_key = input(\"CDS API key (uid:api-key): \").strip()\n",
    "    with open(cds_config_path, \"w\") as f:\n",
    "        f.write(\"url: https://cds.climate.copernicus.eu/api\\n\")\n",
    "        f.write(f\"key: {cds_key}\\n\")\n",
    "    ensure_permission(cds_config_path)\n",
    "    print(\"CDS API config created.\")\n",
    "else:\n",
    "    print(\"CDS API config file detected. (Ensure it is current)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939e0c7-6b25-488a-a4b6-c5fc72b3a7de",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "<a id='prep_ifg'></a>\n",
    "## 1. Download and Prepare Interferograms\n",
    "\n",
    "In this initial processing step, all the necessary Level-2 unwrapped interferogram products are gathered, organized and reduced to a common grid for analysis with MintPy. Ascending and descending stacks of nearest-neighbor and skip-1 interferograms will be prepared for independent analysis. We use the open-source ARIA-tools package to download processed L2 interferograms over selected cal/val regions from the Alaska Satellite Facility archive and to stitch/crop the frame-based NISAR GUNW products to stacks that can be directly ingested into MintPy for time-series processing. ARIA-tools uses a phase-minimization approach in the product overlap region to stitch the unwrapped and ionospheric phase, a mosaicing approach for coherence and amplitude, and extracts the geometric information from the 3D data cubes through a mosaicking of the 3D datacubes and subsequent intersection with a DEM.\n",
    "\n",
    "REFERENCE: https://github.com/aria-tools/ARIA-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9d838-98b7-4289-a5f7-d1ab2c3f8cec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1. Download GUNW Interferograms <a id='prep_download_ifg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89439c3f-783c-492b-b57e-93fecbf3d35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"CalVal site: {site}\")\n",
    "\n",
    "# Extract site-specific metadata\n",
    "bbox = site_info.get('download_region')\n",
    "startdate = site_info.get('download_start_date')\n",
    "enddate = site_info.get('download_end_date')\n",
    "track = site_info.get('sentinel_track')\n",
    "\n",
    "# Base command template\n",
    "aria_cmd_template = (\n",
    "    \"ariaDownload.py --num_threads 8 \"\n",
    "    \"-b {bbox} -u {user} -p \\\"{password}\\\" \"\n",
    "    \"-s {start} -e {end} -t {track} \"\n",
    "    \"--workdir {workdir} --version {version} -o {output}\"\n",
    ")\n",
    "\n",
    "# Define common formatting args\n",
    "common_args = dict(\n",
    "    bbox=bbox,\n",
    "    start=startdate,\n",
    "    end=enddate,\n",
    "    track=track,\n",
    "    version=aria_gunw_version,\n",
    "    user=earthdata_user,\n",
    "    password=earthdata_password,\n",
    "    workdir=gunw_dir\n",
    ")\n",
    "\n",
    "# Step 1: Count available GUNW products\n",
    "count_cmd = aria_cmd_template.format(**common_args, output=\"count\")\n",
    "subprocess.run(count_cmd, text=True, shell=True, check=True)\n",
    "\n",
    "# Step 2: Generate URL list\n",
    "url_cmd = aria_cmd_template.format(**common_args, output=\"Url\")\n",
    "subprocess.run(url_cmd, text=True, shell=True, check=True)\n",
    "\n",
    "# Step 3: Download GUNW products\n",
    "print(\"Starting GUNW download...\")\n",
    "download_cmd = aria_cmd_template.format(**common_args, output=\"Download\")\n",
    "subprocess.run(download_cmd, text=True, shell=True, check=True)\n",
    "print(\"Finished GUNW download.\")\n",
    "\n",
    "# Cleanup unnecessary files\n",
    "cleanup_files = [\"avg_rates.csv\", \"ASFDataDload0.py\", \"AvgDlSpeed.png\", \"error.log\"]\n",
    "for filename in cleanup_files:\n",
    "    for path in [gunw_dir, work_dir]:\n",
    "        full_path = os.path.join(path, filename)\n",
    "        if os.path.exists(full_path):\n",
    "            print(f\"Cleaning file {full_path}\")\n",
    "            os.remove(full_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51f44d-b58d-4862-885c-180e8e5c3df6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2. Crop and Mask Interferograms <a id='prep_crop_ifg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9211df-fd07-4ad2-a6c4-6890ddeaf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date range from site metadata\n",
    "start_date = int(site_info.get('download_start_date'))\n",
    "end_date = int(site_info.get('download_end_date'))\n",
    "\n",
    "# Filter GUNW files based on date range and version\n",
    "gunw_list = []\n",
    "for filename in os.listdir(gunw_dir):\n",
    "    if not filename.endswith(\".nc\"):\n",
    "        continue\n",
    "    if aria_gunw_version not in filename:\n",
    "        continue\n",
    "    try:\n",
    "        date1 = int(filename[30:38])  # reference date\n",
    "        date2 = int(filename[21:29])  # secondary date\n",
    "        if start_date <= date1 and date2 <= end_date:\n",
    "            gunw_list.append(os.path.join(gunw_dir, filename))\n",
    "    except (ValueError, IndexError):\n",
    "        print(f\"Warning: Skipping malformed filename: {filename}\")\n",
    "\n",
    "# Sort and write list to product file\n",
    "gunw_list.sort()\n",
    "product_file = os.path.join(work_dir, \"product_file.txt\")\n",
    "with open(product_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(gunw_list))\n",
    "\n",
    "print(f\"Wrote {len(gunw_list)} GUNW files to: {product_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91838e-b2d7-424e-87c5-020202788410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optional correction layers based on site metadata\n",
    "optional_layers = []\n",
    "\n",
    "layer_conditions = [\n",
    "    (\"solidEarthTide\", site_info.get('do_SET') == 'True'),\n",
    "    (\"ionosphere\", site_info.get('do_iono') == 'True'),\n",
    "    (\"troposphereTotal\", (\n",
    "        site_info.get('do_tropo') == 'True' and \n",
    "        site_info.get('tropo_model') == 'HRRR'\n",
    "    ))\n",
    "]\n",
    "\n",
    "optional_layers = [layer for layer, condition in layer_conditions if condition]\n",
    "\n",
    "print(f\"Optional correction layers {optional_layers} will be extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c00fe-8108-42ed-83ce-efff73f779d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Move to working directory\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Check if stacks already exists and extract if not\n",
    "stack_dir = os.path.join(work_dir, 'stack')\n",
    "if not os.path.exists(stack_dir):\n",
    "    print('Preparing GUNWs for MintPy...')\n",
    "\n",
    "    # Construct base command\n",
    "    cmd_parts = [\n",
    "        \"ariaTSsetup.py\",\n",
    "        f\"-f {product_file}\",\n",
    "        f\"-b {site_info.get('analysis_region')}\",\n",
    "        f\"-l '{', '.join(optional_layers)}'\",\n",
    "        \"--croptounion\",\n",
    "        \"-nt 8\",\n",
    "        \"--log-level info\"\n",
    "    ]\n",
    "\n",
    "    # Add water mask option if enabled\n",
    "    if site_info.get('maskWater') != 'False':\n",
    "        cmd_parts.append(\"--mask Download\")\n",
    "\n",
    "    # Run ariaTSsetup.py\n",
    "    subprocess.run(\" \".join(cmd_parts), shell=True, text=True)\n",
    "\n",
    "else:\n",
    "    print(\"Stack directory detected and not overwritten.\")\n",
    "\n",
    "\n",
    "# Update mask file\n",
    "mask_file = glob.glob(f\"{work_dir}/mask/*.msk\")\n",
    "if len(mask_file) == 1:\n",
    "    mask_file = mask_file[0]\n",
    "else:\n",
    "    mask_file = \"auto\"\n",
    "\n",
    "print(f\"Water mask file: {mask_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53015f-e3d6-4ba7-8550-9ced8b2584ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3. Set Up MintPy Configuration file <a id='prep_setup_config'></a>\n",
    "\n",
    "The default processing parameters for MintPy's **smallbaselineApp.py** need to be modified by including the following lines in config_file (which must be manually created and placed into mint_dir):\n",
    "\n",
    "- mintpy.load.processor      = aria\n",
    "- mintpy.compute.cluster     = local\n",
    "- mintpy.compute.numWorker   = auto\n",
    "- mintpy.load.unwFile        = ../stack/unwrapStack.vrt\n",
    "- mintpy.load.corFile        = ../stack/cohStack.vrt\n",
    "- mintpy.load.connCompFile   = ../stack/connCompStack.vrt\n",
    "- mintpy.load.demFile        = ../DEM/SRTM_3arcsec.dem\n",
    "- mintpy.load.incAngleFile   = ../incidenceAngle/{download_start_date}_{download_edn_date}.vrt\n",
    "- mintpy.load.azAngleFile    = ../azimuthAngle/{download_start_date}_{download_edn_date}.vrt\n",
    "- mintpy.load.waterMaskFile  = ../mask/watermask.msk\n",
    "- mintpy.reference.lalo      = auto, or somewhere in your bounding box\n",
    "- mintpy.topographicResidual.pixelwiseGeometry = no\n",
    "- mintpy.troposphericDelay.method              = no\n",
    "- mintpy.topographicResidual                   = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e01b2-91ea-48fa-8a0f-69f58303d9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(mintpy_dir)\n",
    "\n",
    "# Build config as a dictionary first\n",
    "config_file_content = {\n",
    "    \"mintpy.load.processor\": \"aria\",\n",
    "    \"mintpy.compute.cluster\": \"local\",\n",
    "    \"mintpy.compute.numWorker\": \"auto\",\n",
    "    \"mintpy.load.unwFile\": f\"{work_dir}/stack/unwrapStack.vrt\",\n",
    "    \"mintpy.load.corFile\": f\"{work_dir}/stack/cohStack.vrt\",\n",
    "    \"mintpy.load.connCompFile\": f\"{work_dir}/stack/connCompStack.vrt\",\n",
    "    \"mintpy.load.demFile\": f\"{work_dir}/DEM/glo_90.dem\",\n",
    "    \"mintpy.load.incAngleFile\": f\"{work_dir}/incidenceAngle/*.vrt\",\n",
    "    \"mintpy.load.azAngleFile\": f\"{work_dir}/azimuthAngle/*.vrt\",\n",
    "    \"mintpy.load.waterMaskFile\": mask_file,\n",
    "    \"mintpy.topographicResidual.pixelwiseGeometry\": \"no\",\n",
    "    \"mintpy.troposphericDelay.method\": \"no\",\n",
    "    \"mintpy.topographicResidual\": \"no\",\n",
    "    \"mintpy.network.tempBaseMax\": site_info.get('tempBaseMax'),\n",
    "    \"mintpy.network.startDate\": site_info.get('download_start_date'),\n",
    "    \"mintpy.network.endDate\": site_info.get('download_end_date'),\n",
    "    \"mintpy.velocity.startDate\": site_info.get('download_start_date'),\n",
    "    \"mintpy.velocity.endDate\": site_info.get('download_end_date'),\n",
    "    \"mintpy.reference.lalo\": site_info.get('reference_lalo'),\n",
    "    \"mintpy.network.excludeDate12\": site_info.get('ifgExcludePair'),\n",
    "    \"mintpy.network.excludeDate\" : site_info.get('ifgExcludeDate'),\n",
    "    \"mintpy.network.excludeIfgIndex\" : site_info.get('ifgExcludeIndex'),\n",
    "}\n",
    "\n",
    "# Write config dictionary to text file\n",
    "with open(config_file, \"w\") as f:\n",
    "    f.writelines(f\"{k} = {v}\\n\" for k, v in config_file_content.items())\n",
    "\n",
    "# Confirm output\n",
    "print(f\"MintPy config file written to:\\n    {config_file}\\n\")\n",
    "with open(config_file, \"r\") as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4a38e-60f3-421b-949f-aff1145e5881",
   "metadata": {},
   "source": [
    "### 1.4. Load Data into MintPy Cubes <a id='prep_load_data'></a>\n",
    "\n",
    "The output of this step is an \"inputs\" directory in 'calval_directory/calval_location/MintPy/\" containing two HDF5 files:\n",
    "- ifgramStack.h5: This file contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata\n",
    "- geometryGeo.h5: This file contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e4a4a-c390-439f-bc97-2072b9ce9f10",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> If you plan to use one or more ARIA GUNW correction layers — such as <b>troposphere</b>, <b>ionosphere</b>, or <b>solid Earth tides</b> — run <b>Section 1.4.2</b> <code>prep_aria.py</code> command in the second cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad69da-bd51-4f40-9975-16863a131cac",
   "metadata": {},
   "source": [
    "#### 1.4.1 Use `smallbaselineApp.py` to generate MintPy stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300656a7-ccc6-469c-a9db-6fa68adc8f00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only loads the ifgram\n",
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep load_data'\n",
    "process = subprocess.run(command, shell=True)\n",
    "print('Mintpy input files:')\n",
    "[x for x in os.listdir('inputs') if x.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf2c62-6f47-4922-bc25-659645380d56",
   "metadata": {},
   "source": [
    "#### 1.4.2 Use `prep_aria.py` to generate MintPy stacks, including optional corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671415cf-b6b5-412a-af67-c94358d4bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths from MintPy config file content\n",
    "stack_dir = config_file_content['mintpy.load.unwFile'].split('/unwrapStack.vrt')[0]\n",
    "dem_f = config_file_content['mintpy.load.demFile']\n",
    "incAngle_f = config_file_content['mintpy.load.incAngleFile']\n",
    "azAngle_f = config_file_content['mintpy.load.azAngleFile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3a44c-8ea0-4bb6-970e-704581ef107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optional correction file paths if enabled and file exists\n",
    "solidearthtides_f = None\n",
    "ionosphere_f = None\n",
    "troposphere_f = None\n",
    "\n",
    "# Solid Earth Tides correction\n",
    "if site_info.get('do_SET') == 'True':\n",
    "    path = os.path.join(stack_dir, 'setStack.vrt')\n",
    "    if os.path.isfile(path):\n",
    "        solidearthtides_f = path\n",
    "        print(f\"Found: {solidearthtides_f}\")\n",
    "    else:\n",
    "        print(f\"File Not Found: {path}\")\n",
    "\n",
    "# Ionosphere correction\n",
    "if site_info.get('do_iono') == 'True':\n",
    "    path = os.path.join(stack_dir, 'ionoStack.vrt')\n",
    "    if os.path.isfile(path):\n",
    "        ionosphere_f = path\n",
    "        print(f\"Found: {ionosphere_f}\")\n",
    "    else:\n",
    "        print(f\"File Not Found: {path}\")\n",
    "\n",
    "# Troposphere correction\n",
    "if site_info.get('do_tropo') == 'True' and site_info.get('tropo_model') == 'HRRR':\n",
    "    path = os.path.join(stack_dir, 'troposphereTotal', 'HRRRStack.vrt')\n",
    "    if os.path.isfile(path):\n",
    "        troposphere_f = path\n",
    "        print(f\"Found: {troposphere_f}\")\n",
    "    else:\n",
    "        print(f\"File Not Found: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4f7f0-eb5e-47d6-ac0c-2b36f1627218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "command = (f\"prep_aria.py -s {stack_dir} -d {dem_f} \"\n",
    "           f\"-i {incAngle_f} -a {azAngle_f} -w {mask_file} \"\n",
    "           f\"--set {solidearthtides_f} --tropo {troposphere_f} --iono {ionosphere_f}\")\n",
    "process = subprocess.run(command, shell=True)\n",
    "\n",
    "print('Mintpy input files:')\n",
    "[x for x in os.listdir('inputs') if x.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c846c09-26ea-4ea9-901c-55fd77bfcf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (solid_earth_atbd_dev)",
   "language": "python",
   "name": "solid_earth_atbd_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
