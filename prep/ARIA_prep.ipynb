{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8d77a2-b3ea-47a1-9f9f-f49d0ed160ab",
   "metadata": {},
   "source": [
    "# Preparing ARIA Sentinel-1 data for validation of Solid Earth requirements\n",
    "\n",
    "**Original code authored by:** David Bekaert, Heresh Fattahi, Eric Fielding, and Zhang Yunjun \n",
    "\n",
    "Extensive modifications by Adrian Borsa and Amy Whetter 2022\n",
    "\n",
    "Reorganized and modified by Ekaterina Tymofyeyeva, March 2024\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Both the initial setup (<b>Prep A</b> section) and download of the data (<b>Prep B</b> section) should be run at the start of the notebook. Methods for validation of transient, secular, and coseismic requirements using Sentinel-1 ARIA data can be run subsequently.\n",
    "</div>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## Define CalVal Site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe37bbc-647b-4738-b0ee-9a7e668f87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose a site and track direction\n",
    "site='MojaveD173' \n",
    "\n",
    "# Choose the requirement you are going to validate\n",
    "requirement='Coseismic' # 'Secular' 'Coseismic' 'Transient'\n",
    "\n",
    "# What dataset are you processing?\n",
    "dataset = 'ARIA_S1' # For Sentinel-1 testing with aria-tools\n",
    "\n",
    "# The date and version of this Cal/Val run\n",
    "today = '20240528'\n",
    "version = '1'\n",
    "\n",
    "# Define your directory structure - you won't need to change this line\n",
    "start_directory = '/scratch/nisar-st-calval-solidearth' \n",
    "\n",
    "# The file where you keep your customized list of sites.\n",
    "custom_sites = '/home/jovyan/my_sites.txt'\n",
    "\n",
    "# Please enter a name or username that will determine where your outputs are stored\n",
    "import os\n",
    "if os.path.exists('/home/jovyan/me.txt'): # if OpenTopo API key already installed\n",
    "    with open('/home/jovyan/me.txt') as m:\n",
    "        you = m.readline().strip()\n",
    "    print('You are', you)\n",
    "    print('Using this as the name of the directory where your outputs will be stored.')\n",
    "    print('Directory structure: start_directory / dataset/ requirement / site / you / today / version ')\n",
    "else:\n",
    "    print('We need a name or username (determines where your outputs will be stored)')\n",
    "    print('Directory structure: start_directory / dataset/ requirement / site / you / today / version ')\n",
    "    you = input('Please type your name:')\n",
    "    with open ('/home/jovyan/me.txt', 'w') as m: \n",
    "        m.write(you)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966727d-26c2-454f-b69e-2c06db36d94b",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "<a id='prep_TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397daf73-728b-4e62-a25e-2d321f41384f",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "[**Prep A. Environment Setup**](#prep_a)\n",
    "\n",
    "[**Prep B. Data Staging**](#prep_b)\n",
    "\n",
    "[**1. Generate Interferogram Stack**](#prep_gen_ifg)\n",
    "- [1.1.  Crop Interferograms](#prep_crop_ifg)\n",
    "\n",
    "[**2. Generation of Time Series from Interferograms**](#prep_gen_ts)\n",
    "- [2.1. Set Up MintPy Configuration file](#prep_setup_config)\n",
    "- [2.2. Load Data into MintPy](#prep_load_data)\n",
    "- [2.3. Validate/Modify Interferogram Network](#secular_validate_network)\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00c720-2ba2-4843-a667-f2411f468204",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='secular_prep_a'></a>\n",
    "## Prep A. Environment Setup\n",
    "Setup your environment for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dade5f-c3f9-4222-a71e-08a4bb434145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load Packages\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import netrc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mintpy.cli import view, plot_network\n",
    "from mintpy.objects import gnss, timeseries\n",
    "from mintpy.smallbaselineApp import TimeSeriesAnalysis\n",
    "from mintpy.utils import ptime, readfile, utils as ut\n",
    "from scipy import signal\n",
    "\n",
    "from solid_utils.sampling import load_geo, samp_pair, profile_samples, haversine_distance\n",
    "\n",
    "#Set Global Plot Parameters\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "################# Set Directories ##########################################\n",
    "work_dir = os.path.join(start_directory,dataset,requirement,site,you,today,'v'+version)\n",
    "\n",
    "print(\"Work directory:\", work_dir)\n",
    "os.makedirs(work_dir,exist_ok=True)\n",
    "\n",
    "# Change to Workdir\n",
    "os.chdir(work_dir)\n",
    "\n",
    "gunw_dir = os.path.join(work_dir,'products')\n",
    "os.makedirs(gunw_dir,exist_ok=True)\n",
    "print(\"   GUNW    dir:\", gunw_dir) \n",
    "\n",
    "mintpy_dir = os.path.join(work_dir,'MintPy')\n",
    "os.makedirs(mintpy_dir,exist_ok=True)\n",
    "print(\"   MintPy  dir:\", mintpy_dir)\n",
    "### Change to MintPy workdir\n",
    "os.chdir(mintpy_dir)\n",
    "\n",
    "vel_file = os.path.join(mintpy_dir, 'velocity.h5')\n",
    "msk_file = os.path.join(mintpy_dir, 'maskConnComp.h5')  # maskTempCoh.h5 maskConnComp.h5\n",
    "\n",
    "with open('/home/jovyan/my_sites.txt','r') as fid:\n",
    "    sitedata = json.load(fid)\n",
    "    \n",
    "print(work_dir)\n",
    "\n",
    "sitedata['sites'][site]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939e0c7-6b25-488a-a4b6-c5fc72b3a7de",
   "metadata": {},
   "source": [
    "<a id='secular_prep_b'></a>\n",
    "## Prep B. Data Staging\n",
    "\n",
    "In this initial processing step, all the necessary Level-2 unwrapped interferogram products are gathered, organized and reduced to a common grid for analysis with MintPy. Ascending and descending stacks of nearest-neighbor and skip-1 interferograms will be prepared for independent analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1918d-896d-4220-9b86-bc8722a580bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### 1. Download (Aria) Interferograms from ASF ################\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Search for Earthdata login \n",
    "fnetrc = '/home/jovyan/.netrc'\n",
    "earthdata = False\n",
    "if os.path.exists(fnetrc):\n",
    "    !chmod 0600 /home/jovyan/.netrc\n",
    "    #netrc = netrc.netrc()\n",
    "    remoteHostName  = \"urs.earthdata.nasa.gov\"\n",
    "    with open(fnetrc) as file:\n",
    "        if remoteHostName in file.read():\n",
    "            authTokens = netrc.authenticators(remoteHostName)\n",
    "            earthdata_user = authTokens[0]\n",
    "            earthdata_password = authTokens[2]\n",
    "            earthdata = True\n",
    "            \n",
    "if not earthdata:             \n",
    "    print('NEEDED To Download ARIA GUNWs: \\n Link to create account : https://urs.earthdata.nasa.gov/')\n",
    "    earthdata_user = input('Please type your Earthdata username:')\n",
    "    earthdata_password = input('Please type your Earthdata password:')\n",
    "    with open(fnetrc, 'a') as file:\n",
    "        file.write('machine urs.earthdata.nasa.gov\\n')\n",
    "        file.write('login ' + earthdata_user + '\\n')\n",
    "        file.write('password ' + earthdata_password)\n",
    "    !chmod 0600 /home/jovyan/.netrc\n",
    "\n",
    "print('NEEDED To Download DEMs: \\n Link to create account : https://portal.opentopography.org/login')\n",
    "if os.path.exists('/home/jovyan/.topoapi'): # if OpenTopo API key already installed\n",
    "    print('OpenTopo API key appears to be installed, using that')\n",
    "else:\n",
    "    print('API key location: My Account > myOpenTopo Authorizations and API Key > Request API key')\n",
    "    opentopography_api_key = input('Please type your OpenTopo API key:')\n",
    "\n",
    "######################## USE ARIA-TOOLS TO DOWNLOAD GUNW ########################\n",
    "'''\n",
    "REFERENCE: https://github.com/aria-tools/ARIA-tools\n",
    "'''\n",
    "aria_download = '''ariaDownload.py --num_threads 16 -b {bbox} -u {user} -p {password} -s {start}  -e {end} -t {track} --version 3_0_1 -o Count'''\n",
    "\n",
    "###############################################################################\n",
    "print('CalVal site {}'.format(site))\n",
    "print('  Searching for available GUNW products:\\n')\n",
    "\n",
    "command = aria_download.format(bbox = sitedata['sites'][site]['download_region'],\n",
    "                               start = sitedata['sites'][site]['download_start_date'],\n",
    "                               end = sitedata['sites'][site]['download_end_date'],\n",
    "                               track = sitedata['sites'][site]['sentinel_track'],\n",
    "                               user = earthdata_user,\n",
    "                               password = earthdata_password)\n",
    "\n",
    "process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text = True, shell = True)\n",
    "print(process.stdout)\n",
    "\n",
    "############## Download GUNW ##################\n",
    "print(\"Start downloading GUNW files ...\")\n",
    "#process = subprocess.run(command.split(' -o')[0], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "os.system(command.split(' -o')[0])\n",
    "# Missing progressbar\n",
    "print(\"Downloaded {} GUNW files in: {}\\n\".format(len([(x) for x in os.listdir(gunw_dir) if x.endswith('.nc')]), gunw_dir))\n",
    "\n",
    "############## DO a little CLEANING ###########\n",
    "data_to_clean = [\"avg_rates.csv\", \"ASFDataDload0.py\", \"AvgDlSpeed.png\", \"error.log\"]\n",
    "\n",
    "for i, file in enumerate(data_to_clean):\n",
    "\n",
    "    if os.path.exists(os.path.join(gunw_dir,file)):\n",
    "        print('Cleaning unnecessary data {} in {}'.format(file, gunw_dir))\n",
    "        os.unlink(os.path.join(gunw_dir,file))\n",
    "\n",
    "#Delete error log file from workdir\n",
    "print('Cleaning unnecessary data error.log in {}'.format(work_dir))\n",
    "\n",
    "if os.path.exists(os.path.join(gunw_dir,'error.log')):\n",
    "    os.unlink(os.path.join(work_dir,\"error.log\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34d6ea-49df-4a6f-acc5-6655b55e12a2",
   "metadata": {},
   "source": [
    "<a id='secular_gen_ifg'></a>\n",
    "# 1. Generate Interferogram Stack\n",
    "\n",
    "InSAR time series (i.e., the unfiltered displacement of each pixel vs. time) are estimated from a processed InSAR stack from Section 3.1 (either ascending or descending) using a variant of the small baseline subset (SBAS) approach and then parameterized using the approach described in Section 4. This step uses tools available in the MintPy software package (REF), which provides both SBAS time series and model-based time series parameterization. Recent results on InSAR closure phase and “fading signal” recommend the of use all available interferograms to avoid systematic bias (_Ansari et al._, 2020; _Zheng Y.J. et al._, 2022). As we expect high-quality orbital control for NISAR, we anticipate that the interferogram stack will typically include all nearest-neighbor (i.e., ~12-day pairs) and skip-1 interferograms, which will be the minimum inputs into the SBAS generation step.\n",
    "\n",
    "We use the open-source ARIA-tools package to download processed L2 interferograms over selected cal/val regions from the Alaska Satellite Facility archive and to stitch/crop the frame-based NISAR GUNW products to stacks that can be directly ingested into MintPy for time-series processing. ARIA-tools uses a phase-minimization approach in the product overlap region to stitch the unwrapped and ionospheric phase, a mosaicing approach for coherence and amplitude, and extracts the geometric information from the 3D data cubes through a mosaicking of the 3D datacubes and subsequent intersection with a DEM. ARIA has been used to pre-process NISAR beta products derived from Sentinel-1 which have revealed interseismic deformation and creep along the San Andreas Fault system, along with subsidence, landsliding, and other signals. \n",
    "\n",
    "We use MintPy to validate and modify the InSAR stack, removing interferograms that do not meet minimum coherence criteria, generating a quality control mask for the purpose of identifying noisy pixels within the stack, and referencing estimated deformation to a common location in all interferograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51f44d-b58d-4862-885c-180e8e5c3df6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='secular_crop_ifg'></a>\n",
    "## 1.1. Crop Interferograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87765ed1-9a53-4dca-9525-f9b2161b16a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crop Interferograms to Analysis Region\n",
    "os.chdir(work_dir)\n",
    "mask_file = 'auto'\n",
    "product_glob = '\"'+os.path.join(work_dir,'products','*.nc')+'\"'\n",
    "\n",
    "###########################################################################################################\n",
    "# Set up ARIA product and mask data with GSHHS water mask:\n",
    "'''\n",
    "REQUIRED: Acquire API key to access/download DEMs\n",
    "\n",
    "\n",
    "Follow instructions listed here to generate and access API key through OpenTopography:\n",
    "https://opentopography.org/blog/introducing-api-keys-access-opentopography-global-datasets.\n",
    "'''\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir,'stack')):\n",
    "    if not os.path.exists('/home/jovyan/.topoapi'): # if OpenTopo API key not already installed\n",
    "        os.system('echo \"{api_key}\" > /home/jovyan/.topoapi; chmod 600 /home/jovyan/.topoapi'.format(api_key = str(opentopography_api_key)))\n",
    "    print('Preparing GUNWs for MintPY....')\n",
    "    if sitedata['sites'][site]['maskWater'] != 'False':\n",
    "        mask_file = '../mask/watermask.msk'\n",
    "        command = 'ariaTSsetup.py -f ' + product_glob + ' -b ' + sitedata['sites'][site]['analysis_region'] + ' --mask Download  --croptounion --verbose' # slow\n",
    "    else: # skip slow mask download when we don't need to mask water\n",
    "        command = 'ariaTSsetup.py -f ' + product_glob + ' -b ' + sitedata['sites'][site]['analysis_region'] + ' --croptounion --verbose'\n",
    "\n",
    "    ################################## CROP & PREPARE STACK ###################################################\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    #result = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "print('Finish preparing GUNWs for MintPy!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09370356-d894-4f18-bce0-38653082e712",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='secular_gen_ts'></a>\n",
    "# 2. Creating the MintPy data cube\n",
    "\n",
    "InSAR time series (i.e., the unfiltered displacement of each pixel vs. time) are estimated from a processed InSAR stack from Section 3.1 (either ascending or descending) using a variant of the small baseline subset (SBAS) approach and then parameterized using the approach described in Section 4. This step uses tools available in the MintPy software package (REF), which provides both SBAS time series and model-based time series parameterization. Recent results on InSAR closure phase and “fading signal” recommend the of use all available interferograms to avoid systematic bias (_Ansari et al._, 2020; _Zheng Y.J. et al._, 2022). As we expect high-quality orbital control for NISAR, we anticipate that the interferogram stack will typically include all nearest-neighbor (i.e., ~12-day pairs) and skip-1 interferograms, which will be the minimum inputs into the SBAS generation step.\n",
    "\n",
    "We use the open-source ARIA-tools package to download processed L2 interferograms over selected cal/val regions from the Alaska Satellite Facility archive and to stitch/crop the frame-based NISAR GUNW products to stacks that can be directly ingested into MintPy for time-series processing. ARIA-tools uses a phase-minimization approach in the product overlap region to stitch the unwrapped and ionospheric phase, a mosaicing approach for coherence and amplitude, and extracts the geometric information from the 3D data cubes through a mosaicking of the 3D datacubes and subsequent intersection with a DEM. ARIA has been used to pre-process NISAR beta products derived from Sentinel-1 which have revealed interseismic deformation and creep along the San Andreas Fault system, along with subsidence, landsliding, and other signals. \n",
    "\n",
    "We use MintPy to validate and modify the InSAR stack, removing interferograms that do not meet minimum coherence criteria, generating a quality control mask for the purpose of identifying noisy pixels within the stack, and referencing estimated deformation to a common location in all interferograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53015f-e3d6-4ba7-8550-9ced8b2584ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='secular_setup_config'></a>\n",
    "## 2.1. Set Up MintPy Configuration file\n",
    "\n",
    "\n",
    "The default processing parameters for MintPy's **smallbaselineApp.py** need to be modified by including the following lines in config_file (which must be manually created and placed into mint_dir):\n",
    "\n",
    "- mintpy.load.processor      = aria\n",
    "- mintpy.load.unwFile        = ../stack/unwrapStack.vrt\n",
    "- mintpy.load.corFile        = ../stack/cohStack.vrt\n",
    "- mintpy.load.connCompFile   = ../stack/connCompStack.vrt\n",
    "- mintpy.load.demFile        = ../DEM/SRTM_3arcsec.dem\n",
    "- mintpy.load.incAngleFile   = ../incidenceAngle/{download_start_date}_{download_edn_date}.vrt\n",
    "- mintpy.load.azAngleFile    = ../azimuthAngle/{download_start_date}_{download_edn_date}.vrt\n",
    "- mintpy.load.waterMaskFile  = ../mask/watermask.msk\n",
    "- mintpy.reference.lalo      = auto, or somewhere in your bounding box\n",
    "- mintpy.topographicResidual.pixelwiseGeometry = no\n",
    "- mintpy.troposphericDelay.method              = no\n",
    "- mintpy.topographicResidual                   = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e01b2-91ea-48fa-8a0f-69f58303d9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "### Change to MintPy workdir\n",
    "os.chdir(mintpy_dir)\n",
    "config_file = Path(mintpy_dir)/(sitedata['sites'][site]['calval_location'] + '.cfg')\n",
    "\n",
    "####################################################################\n",
    "### Write smallbaseline.py config file\n",
    "config_file_content = \"\"\"\n",
    "mintpy.load.processor = aria\n",
    "mintpy.compute.numWorker = auto\n",
    "mintpy.load.unwFile = {wd}/stack/unwrapStack.vrt\n",
    "mintpy.load.corFile = {wd}/stack/cohStack.vrt\n",
    "mintpy.load.connCompFile = {wd}/stack/connCompStack.vrt\n",
    "mintpy.load.demFile = {wd}/DEM/glo_90.dem\n",
    "mintpy.load.incAngleFile = {wd}/incidenceAngle/*.vrt\n",
    "mintpy.load.azAngleFile = {wd}/azimuthAngle/*.vrt\n",
    "mintpy.load.waterMaskFile = {mask_file}\n",
    "mintpy.topographicResidual.pixelwiseGeometry = no\n",
    "mintpy.troposphericDelay.method = no\n",
    "mintpy.topographicResidual = no\n",
    "mintpy.network.tempBaseMax = {tempmax}\n",
    "mintpy.network.startDate = {startdatenet}\n",
    "mintpy.network.endDate = {enddatenet}\n",
    "mintpy.velocity.startDate = {startdatevel}\n",
    "mintpy.velocity.endDate = {enddatevel}\n",
    "mintpy.reference.lalo = {reference_lalo}\n",
    "mintpy.network.excludeIfgIndex = {excludeIfg}\"\"\".format(wd = work_dir,\n",
    "                                                        mask_file = mask_file,\n",
    "                                                        tempmax=sitedata['sites'][site]['tempBaseMax'],\n",
    "                                                        excludeIfg=sitedata['sites'][site]['ifgExcludeList'],\n",
    "                                                        startdatenet=sitedata['sites'][site]['download_start_date'],\n",
    "                                                        enddatenet=sitedata['sites'][site]['download_end_date'],\n",
    "                                                        startdatevel=sitedata['sites'][site]['download_start_date'],\n",
    "                                                        enddatevel=sitedata['sites'][site]['download_end_date'],\n",
    "                                                        reference_lalo=sitedata['sites'][site]['reference_lalo'])\n",
    "\n",
    "config_file.write_text(config_file_content)\n",
    "\n",
    "print('MintPy config file:\\n    {}:'.format(config_file))\n",
    "print(config_file.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4a38e-60f3-421b-949f-aff1145e5881",
   "metadata": {},
   "source": [
    "<a id='secular_load_data'></a>\n",
    "## 2.2. Load Data into MintPy\n",
    "\n",
    "The output of this step is an \"inputs\" directory in 'calval_directory/calval_location/MintPy/\" containing two HDF5 files:\n",
    "- ifgramStack.h5: This file contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata\n",
    "- geometryGeo.h5: This file contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300656a7-ccc6-469c-a9db-6fa68adc8f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#os.chdir(work_dir)\n",
    "command = 'smallbaselineApp.py ' + str(config_file) + ' --dostep load_data'\n",
    "process = subprocess.run(command, shell=True)\n",
    "print('Mintpy input files:')\n",
    "[x for x in os.listdir('inputs') if x.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401afd1-f04e-4c25-b1aa-e78ab871dd1f",
   "metadata": {},
   "source": [
    "## 2.3. Clean up! \n",
    "\n",
    "Remove downloaded files if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb17d4-9f68-4721-b91d-36ef4fca2bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Now that you have successfully created the MintPy data cube, you may want to clean up the downloaded products')\n",
    "cleanup = input('Please type \"Yes\" if you want to delete the files in the \"products\" directory:')\n",
    "if cleanup == \"Yes\" or cleanup == \"YES\" or cleanup == \"yes\":\n",
    "    import shutil\n",
    "    shutil.rmtree(gunw_dir)\n",
    "elif cleanup == \"No\" or cleanup == \"NO\" or cleanup == \"no\":\n",
    "    print('Keeping your downloaded files')\n",
    "else: \n",
    "    print('ERROR: Please try again. Type \"Yes\" or \"No\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886df7e-b809-41f6-88fc-7b808831b844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_earth_atbd",
   "language": "python",
   "name": "solid_earth_atbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
